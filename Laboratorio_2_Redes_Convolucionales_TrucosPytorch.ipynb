{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio_2_Redes_Convolucionales_Diplomado_IA_vAlumnos(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f031867453d849cd8a88412b654d0c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b72c330a9854fd49d82b375b397ea07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f312cf707c74f8fa1e20085828dcdfb",
              "IPY_MODEL_5d965411381043edbd8f29d2cde15d40"
            ]
          }
        },
        "1b72c330a9854fd49d82b375b397ea07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f312cf707c74f8fa1e20085828dcdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14f67981ba984b5796eef827ca84ff6a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25b5504a0fb04dd39d736417253cd4f9"
          }
        },
        "5d965411381043edbd8f29d2cde15d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8de1c122dc844a06a45a2c15651e3894",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [12:10&lt;00:00, 334kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_985cf20380874b2e8a5606e2e8f4f8f6"
          }
        },
        "14f67981ba984b5796eef827ca84ff6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25b5504a0fb04dd39d736417253cd4f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8de1c122dc844a06a45a2c15651e3894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "985cf20380874b2e8a5606e2e8f4f8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/Laboratorio_2_Redes_Convolucionales_TrucosPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzO98wJgjmOd"
      },
      "source": [
        "# Laboratorio 2 - Redes Convolucionales - Diplomado Inteligencia Artificial UC\n",
        "\n",
        "**IMPORTANTE: habrá un bonus de 1 décima para todos aquellos alumnos/as que muestren buen orden en sus respuestas (esto aplica a legibilidad de código, buena redacción, formalidad, organización del jupyter notebook, seguimiento de instrucciones, etc). El criterio lo pondrá cada ayudante corrector. La nota máxima obtenible en el laboratorio es 7.0.**\n",
        "\n",
        "En este laboratorio nos interiorizaremos en cómo funciona Pytorch (https://pytorch.org/), el framework de Facebook para implementar Redes Neuronales Profundas.\n",
        "\n",
        "Vamos a ver varias partes distintas del flujo de entrenamiento, desde cómo cargamos los datos, cómo creamos redes, cómo las entrenamos y cómo validamos su rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og-s3Wv2oEOe"
      },
      "source": [
        "## El Tensor: la unidad fundamental.\n",
        "\n",
        "Los tensores son el elemento fundamental con que trabajarán nuestras redes profundas. Un tensor es simplemente una matriz de n-dimensiones. \n",
        "\n",
        "* En **imágenes**, usamos tensores de 4 dimensiones: 3 dimensiones (alto, ancho y color) más una cuarta dimensión asociada a los elementos del batch.\n",
        "\n",
        "* Cuando trabajamos con **texto** podemos tener tensores en 3 dimensiones (dimensión de embedding, palabras y batch).\n",
        "\n",
        "* Si trabajamos con **videos** tenemos que agregar otra dimensión para el tiempo. En fin, todos estos datos distintos al final se representan como matrices de números en 3, 4 ó 5 dimensiones distintas.\n",
        "\n",
        "Pytorch representa los tensores via la clase torch.Tensor. Todas las redes neuronales que hagamos requieren tensores para poder trabajar. Nuestros datasets no servirán de nada si no podemos transformarlos en tensores que podamos ocupar con nuestras redes. Si han trabajado con *ndarray* de Numpy la forma de ocuparlos es muy similar. Veamos un tensor de ejemplo de 3 dimensiones: ancho, alto y batch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh5omMrW5bUS",
        "outputId": "8c6c477c-5725-4567-de33-eab4981bc1dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "batch_dim = 5\n",
        "ancho = 3\n",
        "alto = 2\n",
        "tensor_ejemplo = torch.randn((batch_dim, ancho, alto)).float() # Tensor aleatorio\n",
        "print(\"El tensor es: {}\\n\".format(tensor_ejemplo))\n",
        "print(\"La forma del tensor es: {}\".format(tensor_ejemplo.shape))\n",
        "print(\"El tipo del tensor es: {}\".format(type(tensor_ejemplo)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El tensor es: tensor([[[-0.8792, -0.1841],\n",
            "         [ 1.5528, -1.3929],\n",
            "         [-0.8759, -0.2893]],\n",
            "\n",
            "        [[ 0.3191,  0.2379],\n",
            "         [ 0.4570,  1.5419],\n",
            "         [-0.0925, -1.2089]],\n",
            "\n",
            "        [[-0.9069, -0.7905],\n",
            "         [ 1.4982,  0.4975],\n",
            "         [-0.2642, -1.1694]],\n",
            "\n",
            "        [[ 0.4632, -0.3811],\n",
            "         [ 0.4738, -0.8035],\n",
            "         [ 0.1699,  0.2663]],\n",
            "\n",
            "        [[-0.2404,  0.0367],\n",
            "         [ 0.3341,  0.4253],\n",
            "         [ 1.0422,  1.2033]]])\n",
            "\n",
            "La forma del tensor es: torch.Size([5, 3, 2])\n",
            "El tipo del tensor es: <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHpZ99Rvjgte"
      },
      "source": [
        "Crear un tensor desde un arreglo de Python es sencillo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn84KtqwjObX",
        "outputId": "8689b75f-d669-4dc1-8684-30717354c4e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arreglo = [[1, 2, 3], [4, 5, 6]]\n",
        "tensor_desde_arreglo = torch.tensor(arreglo)\n",
        "print(tensor_desde_arreglo, tensor_desde_arreglo.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]]) torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwE7bG-56rx6"
      },
      "source": [
        "Uno trabaja los tensores de la misma manera que cualquier otra variable numérica en Python. Se pueden, sumar y restar sin problema. La multiplicación por escalares no supone problema y la multiplicación de tensores también está soportada.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH-U3PPi7az0",
        "outputId": "6f44b51f-d229-45e8-9639-cd3e5a36fd24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor_1 = torch.randn((1,2,3))\n",
        "tensor_2 = torch.randn((1,2,3))\n",
        "\n",
        "tensor_3 = tensor_1 + tensor_2\n",
        "\n",
        "print(tensor_1)\n",
        "print(tensor_2)\n",
        "print(tensor_3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.7497, -0.3005, -2.2081],\n",
            "         [-0.3230, -0.3719,  0.5118]]])\n",
            "tensor([[[ 1.2712,  0.0515,  1.2329],\n",
            "         [ 2.4661,  0.2007, -0.2772]]])\n",
            "tensor([[[ 0.5215, -0.2490, -0.9752],\n",
            "         [ 2.1431, -0.1712,  0.2346]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoNoKKFATdEv"
      },
      "source": [
        "Podemos indexarlos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OUPry8-TcGX",
        "outputId": "b1127b8d-1a7e-4926-e083-4af5a6709521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensor_indexado = tensor_1[:,:,:2]\n",
        "print(tensor_indexado, tensor_indexado.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.7497, -0.3005],\n",
            "         [-0.3230, -0.3719]]]) torch.Size([1, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGAdf1Zz7a8T"
      },
      "source": [
        "#### Sobre la dimensión batch\n",
        "\n",
        "La dimensión de batch es importante pues es la que nos permite poder entrenar de forma paralela en nuestras GPUs. El estándar de Pytorch es que ésta es la primera dimensión de nuestros tensores siempre. Aunque solo evaluar un elemento en nuestra red, este debe tener una dimensión de batch en su primer lugar o sino no funcionará. También es necesario mencionar que Pytorch espera siempre que la dimensión del canal vaya antes que las dimensiones de ancho y alto en imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX3ER77PS_H_"
      },
      "source": [
        "### Sobre el dispositivo asociado\n",
        "\n",
        "Los tensores son procesados por la CPU o por una GPU. Como quizás hemos escuchado antes, sabemos que parte de la explosión de Deep Learning viene por la disponibilidad de GPUs cada vez más poderosas. Para poder trabajar en GPU un tensor tenemos que hacer lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ln8Wq3wURfu"
      },
      "source": [
        "tensor_nuevo = torch.randn((1,2,3))     # Por defecto el tensor está en CPU\n",
        "tensor_nuevo_gpu = tensor_nuevo.cuda()  # Creé una copia de tensor_nuevo en GPU!\n",
        "otra_forma = tensor_nuevo.to('cuda')    # Creé otra copia de tensor_nuevo en GPU!"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JmfrUSLkF2o"
      },
      "source": [
        "## Definición del Modelo\n",
        "Como vimos en el laboratorio pasado, definir un modelo de aprendizaje profundo consiste en definir una nueva clase que herede de torch.nn.Module.\n",
        "\n",
        "Esta clase debe implementar dos métodos para funcionar como un modelo válido en Pytorch:\n",
        "\n",
        "* Método \\_\\_init\\_\\_(self): el constructor de la clase. Aquí es donde usualmente definiremos todos los elementos arquitéctonicos de nuestra red. Aquí definiremos que capas tendrá, qué funciones de activación, funciones de pooling, etc.\n",
        "\n",
        "* Método forward(self, input): define las conexiones entre capas del modelo, o cómo debe fluir la información que entra en él. Debe retornar un tensor.\n",
        "\n",
        "### Elementos arquitectónicos\n",
        "\n",
        "Todos estos elementos están definidos en el paquete torch.nn (de Neural Networks). Todos derivan de la clase torch.nn.Module.\n",
        "\n",
        "* **Linear:** capa lineal. Toma como parámetros las cantidades de neuronas de entrada y de salida.\n",
        "* **Conv1d, Conv2d, Conv3d**: capas convolucionales de 1, 2 y 3 dimensiones respectivamente. Definidas por el tamaño del kernel que ocupan, el *stride*, filtros de entrada y de salida.\n",
        "* **ReLU**: función de activación. No tiene parámetros.\n",
        "* **Sigmoid**: función de activación. No tiene parámetros.\n",
        "* **Softmax**: capa que transforma el output en una distribución de probabilidad. Parámetro es sobre la o las dimensiones que se aplica.\n",
        "* **MaxPool1d, MaxPool2d, MaxPool3d**: Funciones de pooling en 1,2 y 3 dimensiones respectivamente.\n",
        "* **Dropout**: capa que deja en 0 neuronas con probabilidad $p$. Parámetro: $p$.\n",
        "* **BatchNorm2d**: capa que normaliza el input de acuerdo a una media y varianza aprendidas. \n",
        "* **Sequential**: es un agrupador de Módulos. Se encarga de que la información fluya de forma secuencial entre los módulos que contiene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6fz8KLbXfXJ",
        "outputId": "dcb68a9e-3b67-4241-c2ba-25283772ddec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU, Sigmoid, Sequential, Softmax, BatchNorm1d, BatchNorm2d, Dropout\n",
        "\n",
        "tensor_prueba = torch.randn((3, 5))\n",
        "\n",
        "print(tensor_prueba, tensor_prueba.shape)\n",
        "\n",
        "# Capa Lineal que va de 5 dimensiones a 8\n",
        "capa_lineal = Linear(5, 8)\n",
        "tensor_nuevo = capa_lineal(tensor_prueba)\n",
        "print(\"Tensor después de Capa Lineal:\")\n",
        "print(tensor_nuevo, tensor_nuevo.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.6083,  1.8658,  0.9168,  0.7362,  1.2499],\n",
            "        [-0.4829, -1.4642, -1.3070,  0.9933, -0.3444],\n",
            "        [ 0.2388, -0.6380, -0.3682, -0.3318,  1.8414]]) torch.Size([3, 5])\n",
            "Tensor después de Capa Lineal:\n",
            "tensor([[-1.5293e-01,  4.5815e-01, -1.3909e+00,  2.4302e-01, -5.3591e-04,\n",
            "         -9.6161e-01,  1.4203e+00, -4.2440e-01],\n",
            "        [-6.4542e-01,  5.8697e-01,  8.6491e-01, -7.7866e-02, -9.3024e-01,\n",
            "          4.4392e-01, -6.5902e-01,  8.9367e-01],\n",
            "        [ 3.9432e-01,  2.9768e-01,  3.0648e-01,  2.9039e-01, -6.0792e-01,\n",
            "         -2.6730e-01,  2.0955e-01, -1.2871e-01]], grad_fn=<AddmmBackward>) torch.Size([3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6q_9qzcFiP",
        "outputId": "9e01f98d-a05d-4bf8-f962-0e7120313921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Funciones de Activación\n",
        "# ReLU\n",
        "relu = ReLU()\n",
        "print(\"Antes de ReLU: \")\n",
        "print(tensor_prueba)\n",
        "print(\"Después de ReLU: \")\n",
        "print(relu(tensor_prueba))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de ReLU: \n",
            "tensor([[ 1.6083,  1.8658,  0.9168,  0.7362,  1.2499],\n",
            "        [-0.4829, -1.4642, -1.3070,  0.9933, -0.3444],\n",
            "        [ 0.2388, -0.6380, -0.3682, -0.3318,  1.8414]])\n",
            "Después de ReLU: \n",
            "tensor([[1.6083, 1.8658, 0.9168, 0.7362, 1.2499],\n",
            "        [0.0000, 0.0000, 0.0000, 0.9933, 0.0000],\n",
            "        [0.2388, 0.0000, 0.0000, 0.0000, 1.8414]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL3sBxCbcLty",
        "outputId": "cd1a1dcf-852a-4e01-a3fc-65cfd0379cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sigmoid\n",
        "s = Sigmoid()\n",
        "print(\"Antes de Sigmoid: \")\n",
        "print(tensor_prueba)\n",
        "print(\"Después de Sigmoid: \")\n",
        "print(s(tensor_prueba))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de Sigmoid: \n",
            "tensor([[ 1.6083,  1.8658,  0.9168,  0.7362,  1.2499],\n",
            "        [-0.4829, -1.4642, -1.3070,  0.9933, -0.3444],\n",
            "        [ 0.2388, -0.6380, -0.3682, -0.3318,  1.8414]])\n",
            "Después de Sigmoid: \n",
            "tensor([[0.8332, 0.8660, 0.7144, 0.6762, 0.7773],\n",
            "        [0.3816, 0.1878, 0.2130, 0.7297, 0.4147],\n",
            "        [0.5594, 0.3457, 0.4090, 0.4178, 0.8631]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pRxMMlacFpR",
        "outputId": "8be2fbe3-a77e-455e-f38c-9f1efcad2d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Softmax\n",
        "soft = Softmax(dim=1)\n",
        "print(\"Antes de Softmax: \")\n",
        "print(tensor_prueba)\n",
        "print(\"Después de Softmax: \")\n",
        "soft_tensor = soft(tensor_prueba)\n",
        "print(soft_tensor)\n",
        "print(soft_tensor.sum(dim=1))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes de Softmax: \n",
            "tensor([[ 1.6083,  1.8658,  0.9168,  0.7362,  1.2499],\n",
            "        [-0.4829, -1.4642, -1.3070,  0.9933, -0.3444],\n",
            "        [ 0.2388, -0.6380, -0.3682, -0.3318,  1.8414]])\n",
            "Después de Softmax: \n",
            "tensor([[0.2557, 0.3307, 0.1280, 0.1069, 0.1787],\n",
            "        [0.1363, 0.0511, 0.0598, 0.5964, 0.1565],\n",
            "        [0.1335, 0.0555, 0.0727, 0.0754, 0.6628]])\n",
            "tensor([1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCDkA0IFcFwG",
        "outputId": "8be4fc3c-8458-4194-d473-f8d5132e19ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sequential\n",
        "# Unamos pasos\n",
        "seq = Sequential(capa_lineal, relu, soft)\n",
        "tensor_final = seq(tensor_prueba)\n",
        "print(\"Aplicando Sequential: \")\n",
        "print(tensor_final, tensor_final.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aplicando Sequential: \n",
            "tensor([[0.0834, 0.1318, 0.0834, 0.1063, 0.0834, 0.0834, 0.3450, 0.0834],\n",
            "        [0.0821, 0.1477, 0.1950, 0.0821, 0.0821, 0.1280, 0.0821, 0.2007],\n",
            "        [0.1520, 0.1380, 0.1392, 0.1370, 0.1025, 0.1025, 0.1264, 0.1025]],\n",
            "       grad_fn=<SoftmaxBackward>) torch.Size([3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kImxDES0Zek6",
        "outputId": "0b610217-9682-4dad-f953-df9534e9b732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Dropout\n",
        "drop = Dropout(p=0.15) # con probabilidad de dejar en 0 de 0.15.\n",
        "tensor_dropout = drop(tensor_prueba)\n",
        "print(tensor_dropout)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  2.1950,  1.0786,  0.0000,  0.0000],\n",
            "        [-0.5681, -1.7226, -0.0000,  1.1686, -0.4051],\n",
            "        [ 0.2810, -0.7506, -0.4331, -0.3903,  2.1663]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSpvnCsuZwQo",
        "outputId": "5a54b15b-95cd-4ee6-b3e2-f3fb23cffbb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batch Normalization 1d\n",
        "tensor_lineal = 20*torch.randn((3, 5))  # Una imagen con varianza alta\n",
        "bn = BatchNorm1d(5, momentum=None)                            \n",
        "\n",
        "\n",
        "print(\"La media de los vectores originales por dimensión es: {}\".format(tensor_lineal.mean(dim=[0])))   \n",
        "print(\"La varianza de los vectores originales por dimensión es: {}\".format(tensor_lineal.var(dim=[0], unbiased=False)))\n",
        "print(\"Las medias por dimensión de BN inicialmente son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por dimensión de BN inicialmente son: {}\".format(bn.running_var))\n",
        "\n",
        "tensor_bn = bn(tensor_lineal)\n",
        "\n",
        "print(\"La media por dimensión del resultado es: {}\".format(tensor_bn.mean(dim=[0])))   \n",
        "print(\"La varianza por dimensión del resultado es: {}\".format(tensor_bn.var(dim=[0], unbiased=False)))\n",
        "print(\"Las medias por dimensión de BN ahora son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por dimensión de BN ahora son: {}\".format(bn.running_var))  \n",
        "\n",
        "for n, p in bn.named_parameters():\n",
        "    print(n,p)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de los vectores originales por dimensión es: tensor([  1.5080,   8.3875, -14.0768, -13.0598,  29.1676])\n",
            "La varianza de los vectores originales por dimensión es: tensor([728.3127, 242.1082, 137.0973,   6.4079,  85.1082])\n",
            "Las medias por dimensión de BN inicialmente son: tensor([0., 0., 0., 0., 0.])\n",
            "Las varianzas por dimensión de BN inicialmente son: tensor([1., 1., 1., 1., 1.])\n",
            "La media por dimensión del resultado es: tensor([-2.9802e-08, -5.9605e-08,  3.9736e-08,  0.0000e+00,  0.0000e+00],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "La varianza por dimensión del resultado es: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<VarBackward1>)\n",
            "Las medias por dimensión de BN ahora son: tensor([  1.5080,   8.3875, -14.0768, -13.0598,  29.1676])\n",
            "Las varianzas por dimensión de BN ahora son: tensor([1092.4690,  363.1623,  205.6460,    9.6118,  127.6622])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTjNvAWfocwY",
        "outputId": "3e05f204-527c-4234-aad1-c128c77e6c26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Batch Normalization 2d\n",
        "tensor_imagenes = 20*torch.randn((4, 3, 2, 2))  # 4 Elementos de 3 canales de 2x2.\n",
        "bn = BatchNorm2d(3, momentum = None, eps=0.0)   # 3 es el número de canales\n",
        "print(tensor_imagenes)                           \n",
        "\n",
        "\n",
        "print(\"La media de las imágenes originales por canal es: {}\".format(tensor_imagenes.mean(dim=[0,2,3])))   \n",
        "print(\"La varianza de las imágenes originales por canal es: {}\".format(tensor_imagenes.var(dim=[0,2,3], unbiased=False)))\n",
        "print(\"Las medias por canal de BN inicialmente son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por canal de BN inicialmente son: {}\".format(bn.running_var))\n",
        "\n",
        "tensor_bn = bn(tensor_imagenes)\n",
        "\n",
        "print(\"La media por canal es: {}\".format(tensor_bn.mean(dim=[0,2,3])))   \n",
        "print(\"La varianza por canal es: {}\".format(tensor_bn.var(dim=[0,2,3], unbiased=False)))\n",
        "print(\"Las medias por canal de BN ahora son: {}\".format(bn.running_mean))\n",
        "print(\"Las varianzas por canal de BN ahora son: {}\".format(bn.running_var))\n",
        "\n",
        "for n, p in bn.named_parameters():\n",
        "    print(n,p)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[  9.1407,  -1.3357],\n",
            "          [-42.2134, -29.0140]],\n",
            "\n",
            "         [[-22.6800, -19.9026],\n",
            "          [-45.1152,  19.7088]],\n",
            "\n",
            "         [[ 24.5986, -16.6565],\n",
            "          [ -3.8472, -24.7460]]],\n",
            "\n",
            "\n",
            "        [[[ 29.8513,  -0.4570],\n",
            "          [ 17.8772,   6.9194]],\n",
            "\n",
            "         [[ 35.4112, -33.8903],\n",
            "          [ 17.3039,  20.4116]],\n",
            "\n",
            "         [[ 13.0951,  23.6489],\n",
            "          [ 20.3466,  -6.1332]]],\n",
            "\n",
            "\n",
            "        [[[  3.7902,  -2.9561],\n",
            "          [-17.8929,   4.6190]],\n",
            "\n",
            "         [[ 13.6385,   4.9353],\n",
            "          [ 40.7378,  53.0793]],\n",
            "\n",
            "         [[ 25.7320,  -3.8805],\n",
            "          [ 50.7532, -15.4557]]],\n",
            "\n",
            "\n",
            "        [[[ 24.8102,  12.4029],\n",
            "          [  9.4144,   8.3538]],\n",
            "\n",
            "         [[ 24.0169,  20.4122],\n",
            "          [ -8.0655,  16.0765]],\n",
            "\n",
            "         [[-23.9125,  -9.3114],\n",
            "          [  4.9112, -14.4618]]]])\n",
            "La media de las imágenes originales por canal es: tensor([2.0819, 8.5049, 2.7926])\n",
            "La varianza de las imágenes originales por canal es: tensor([324.4341, 706.2422, 434.4383])\n",
            "Las medias por canal de BN inicialmente son: tensor([0., 0., 0.])\n",
            "Las varianzas por canal de BN inicialmente son: tensor([1., 1., 1.])\n",
            "La media por canal es: tensor([-1.4901e-08, -7.4506e-09,  0.0000e+00], grad_fn=<MeanBackward1>)\n",
            "La varianza por canal es: tensor([1.0000, 1.0000, 1.0000], grad_fn=<VarBackward1>)\n",
            "Las medias por canal de BN ahora son: tensor([2.0819, 8.5049, 2.7926])\n",
            "Las varianzas por canal de BN ahora son: tensor([346.0630, 753.3251, 463.4009])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNvplXz5xkUZ"
      },
      "source": [
        "### Revisitando AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGXdKoKfxkaa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSvQo9EFkFz2"
      },
      "source": [
        "## Manejo de Datos\n",
        "\n",
        "En un problema normal de Machine Learning, usualmente la gestión de datos no era muy importante dado que los datasets en general son pequeños. Sin embargo, dados los volúmenes de datos que requieren los modelos de aprendizaje profundo, se vuelve difícil mantener los datos en memoria. Por esto, se requiere consumirlos de manera parcelada para poder ocuparlos con las restricciones de hardware que tenemos.\n",
        "\n",
        "Pytorch resuelve el problema mediante dos abstracciones: las clases *Dataset* y *DataLoader*. \n",
        "\n",
        "* La clase *Dataset* trabaja como una interfaz sencilla para acceder nuestros datos físicos.\n",
        "* La clase *DataLoader* se encarga de agrupar los elementos de la clase *Dataset* en *batches* para pasarle a nuestro modelo.\n",
        "\n",
        "Usualmente, el mayor trabajo reside en definir una clase Dataset apropiada para nuestro conjunto de datos. Por suerte, si queremos trabajar con ciertos conjuntos de datos estándar, Pytorch ya tiene definido estos datasets por nosotros.\n",
        "\n",
        "Si no, lo único que tenemos que hacer es definir una clase que herede de torch.utils.data.Dataset y que implemente dos métodos:\n",
        "\n",
        "* \\_\\_len(self)\\_\\_: método que devuelva el tamaño total del dataset.\n",
        "* \\_\\_getitem\\_\\_(self, index): método que entregue un elemento particular del dataset dado un índice (index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQI4FW7tm5Kq"
      },
      "source": [
        "### Usar Datasets predefinidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUu0A4sIm56x",
        "outputId": "60b22f87-31c8-4484-92d0-fba0be4a7998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True)\n",
        "cifar = CIFAR10(root=\".\", train=True, download=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Pu0YgnhTNZ"
      },
      "source": [
        "Veamos un ejemplo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcacrRSMhTUs",
        "outputId": "bdcb1303-b867-4da5-ea80-7b475a773798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F9D2110BDA0>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U2JVToqhpas"
      },
      "source": [
        "Vemos que contiene dos elementos: el primero es una imagen en formato PIL y el segundo es la clase asociada a esa imagen (nuestro target o ground truth). La imagen se ve así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuDtFpjheKp",
        "outputId": "f57e9188-8c5d-4093-d231-746282aa3f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from IPython.display import display     # Esto no es Pytorch, es solo una librería\n",
        "                                        # para desplegar imágenes en Colab.\n",
        "display(mnist_train[0][0])\n",
        "display(cifar[0][0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F9D21129630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F9D211295C0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJPBWG9Qh9CD"
      },
      "source": [
        "Sin embargo, una imagen en formato PIL no es un tensor de Pytorch. Tenemos que hacer algo para transformarla! Por suerte para nosotros, Pytorch nos ofrece transformaciones estándar para imágenes, en particular, una para transformar imágenes PIL a tensores. Veamos cómo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw_qKilQiTHk"
      },
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True, transform=ToTensor())"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M-kU58jibL9",
        "outputId": "b00adcad-419b-488e-dd55-573e35d6bfb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train[9]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.7451,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5608, 0.9686, 0.6000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9686, 0.9490, 0.3373,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9882, 0.7333, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.7255, 0.0706, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.3490, 0.9255, 0.8510, 0.1843, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8471, 0.9922, 0.2353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.8314, 1.0000, 0.3176, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.9882, 0.2667, 0.0000,\n",
              "           0.0000, 0.0000, 0.1882, 0.9490, 0.9922, 0.3490, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5137, 0.9843, 0.8314, 0.0824, 0.0000,\n",
              "           0.0000, 0.0431, 0.6549, 0.9882, 0.7725, 0.0196, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1137, 0.9098, 0.9686, 0.2471, 0.0000, 0.0000,\n",
              "           0.0000, 0.6000, 0.9882, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1765, 0.8588, 0.9882, 0.5608, 0.0000, 0.0000, 0.0000,\n",
              "           0.4549, 0.9765, 0.9882, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
              "           0.3765, 0.9922, 1.0000, 0.9922, 0.7843, 0.4784, 0.0275, 0.0980,\n",
              "           0.7882, 0.9804, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608,\n",
              "           0.9882, 0.9882, 0.9922, 0.8510, 0.9882, 0.9882, 0.7843, 0.8902,\n",
              "           0.9882, 0.9059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9843,\n",
              "           0.9686, 0.9059, 0.2549, 0.1882, 0.7412, 0.9882, 0.9882, 0.9922,\n",
              "           0.9882, 0.9843, 0.8902, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8667,\n",
              "           0.3843, 0.0000, 0.0000, 0.0000, 0.1647, 0.7686, 0.9882, 0.9922,\n",
              "           0.9882, 0.9882, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.1137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.9373, 0.9882, 0.3373,\n",
              "           0.1647, 0.1647, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0588, 0.5804, 0.9922, 0.8549, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4745, 0.9882, 0.9059, 0.1098, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1216, 0.8667, 0.9843, 0.5059, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.8549, 0.9882, 0.6275, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4784, 0.9882, 0.3216, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]), 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TgMYxJCifaf"
      },
      "source": [
        "Ahora nuestro Dataset automáticamente transforma las imágenes PIL a tensores de Pytorch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRFZkdKJUOjP"
      },
      "source": [
        "### Crear un Dataset de ejemplo\n",
        "\n",
        "Vamos a crear un Dataset para el conjunto de datos Flowers que vimos el laboratorio pasado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSJdFURr_B8",
        "outputId": "26408202-20d3-4fbe-9173-f523cd28c33d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/q53g4cmpnvzhnhi/flowers.tar.gz -q --show-progress\n",
        "!tar -xzf flowers.tar.gz"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flowers.tar.gz.1    100%[===================>] 328.99M   110MB/s    in 3.0s    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FXcvQ5VUOtH"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "class Flowers(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.imagenes = []       # Vincula el indice con un nombre de archivo\n",
        "        self.imgs_to_class = []  # Vincula el indice con una clase\n",
        "        self.imagenes, self.imgs_to_class = self.armar_indices(root)\n",
        "    \n",
        "    def armar_indices(self, root):\n",
        "        n_classes = len(listdir(root)) # El número de carpetas es la cantidad de clases\n",
        "        contador = 0\n",
        "        lista_imagenes = []\n",
        "        imgs_to_class = []\n",
        "        for clase in listdir(root):\n",
        "            directorio = join(root, clase)\n",
        "            for archivo in listdir(directorio):\n",
        "                lista_imagenes.append(archivo)\n",
        "                contador+=1\n",
        "                imgs_to_class.append(int(clase))\n",
        "\n",
        "        return lista_imagenes, imgs_to_class\n",
        "\n",
        "    def obtener_imagen(self, archivo):\n",
        "\n",
        "        im = Image.open(archivo)\n",
        "        return im\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        nombre_archivo = self.imagenes[idx]\n",
        "        clase = self.imgs_to_class[idx]\n",
        "        ruta_img = join(self.root, str(clase))\n",
        "        ruta_img = join(ruta_img, nombre_archivo)\n",
        "        img = self.obtener_imagen(ruta_img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, clase\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imagenes)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahbf-pLNsW-A",
        "outputId": "9d66f651-d789-47e7-e519-f8db7020e068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "transforms = Compose([Resize((224,224)), ToTensor()])\n",
        "f = Flowers('flowers_dataset/train', transform=transforms)\n",
        "display(f[0])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(tensor([[[0.5843, 0.6275, 0.6314,  ..., 0.3490, 0.1294, 0.0941],\n",
              "          [0.5725, 0.6235, 0.6314,  ..., 0.5255, 0.2902, 0.0902],\n",
              "          [0.5529, 0.6000, 0.6078,  ..., 0.5961, 0.4039, 0.1098],\n",
              "          ...,\n",
              "          [0.1176, 0.0588, 0.0510,  ..., 0.0157, 0.0196, 0.0275],\n",
              "          [0.0627, 0.0196, 0.0471,  ..., 0.0902, 0.1059, 0.1255],\n",
              "          [0.1020, 0.0510, 0.0667,  ..., 0.1373, 0.1373, 0.1569]],\n",
              " \n",
              "         [[0.6157, 0.6745, 0.6863,  ..., 0.3333, 0.1059, 0.0667],\n",
              "          [0.6000, 0.6627, 0.6863,  ..., 0.5137, 0.2667, 0.0667],\n",
              "          [0.5725, 0.6275, 0.6588,  ..., 0.5882, 0.3882, 0.0980],\n",
              "          ...,\n",
              "          [0.1020, 0.0431, 0.0392,  ..., 0.0314, 0.0392, 0.0471],\n",
              "          [0.0510, 0.0196, 0.0667,  ..., 0.0980, 0.1137, 0.1333],\n",
              "          [0.0863, 0.0549, 0.0941,  ..., 0.1412, 0.1412, 0.1608]],\n",
              " \n",
              "         [[0.6510, 0.6980, 0.6980,  ..., 0.3216, 0.0941, 0.0588],\n",
              "          [0.6314, 0.6863, 0.6941,  ..., 0.4980, 0.2510, 0.0510],\n",
              "          [0.6039, 0.6510, 0.6627,  ..., 0.5608, 0.3608, 0.0706],\n",
              "          ...,\n",
              "          [0.0902, 0.0314, 0.0275,  ..., 0.0118, 0.0157, 0.0235],\n",
              "          [0.0431, 0.0118, 0.0510,  ..., 0.0745, 0.0941, 0.1098],\n",
              "          [0.0824, 0.0471, 0.0784,  ..., 0.1216, 0.1216, 0.1412]]]), 66)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PE9qnWDnzjX"
      },
      "source": [
        "### Iterar sobre los datos\n",
        "\n",
        "Dado un Dataset, sea hecho por nosotros o uno predefinido, iterar sobre los datos es muy sencillo. Simplemente tenemos que crear un objeto DataLoader que toma como argumento el Dataset y definir el batch size con que queremos trabajar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9BrWXFcGKKF"
      },
      "source": [
        "Este código iterará por todos los batches de ejemplos de nuestro dataset y parará cuando se acaben. Es decir, esto corre por una **época**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5wPTQwiBx2W",
        "outputId": "dc8e29e6-eaf2-4501-b567-d52149ad4760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dl = DataLoader(f, batch_size=32,shuffle=True)\n",
        "\n",
        "for n_batch, (x, target) in enumerate(train_dl):\n",
        "    print(\"\\rN_Batch: {} input: {}- Label:{}\".format(n_batch, x.shape, target.shape), end=\"\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_Batch: 177 input: torch.Size([23, 3, 224, 224])- Label:torch.Size([23])"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShVxaAFkWY8"
      },
      "source": [
        "## Loop de Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pco2wPSLBlPB"
      },
      "source": [
        "### Optimización\n",
        "\n",
        "¿Como obtenemos los pesos óptimos para nuestra red? Si recordamos nuestras clases anteriores debemos optimizar la función de pérdida para tratar de encontrar los parámetros de nuestra red que minimizan su valor.\n",
        "\n",
        "Primero debemos definir la función de pérdida. Éstas están definidas en torch.nn también. Las usuales son:\n",
        "\n",
        "* CrossEntropyLoss: Entropía Cruzada, mide la distancia entre dos distribuciones de probabilidad. La función de pérdida más común para problemas de clasificación.\n",
        "* MSELoss: Error cuadrático medio. Pérdida usual en problemas de regresión.\n",
        "\n",
        "Hay más para revisar en la documentación de Pytorch (https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "Dado el resultado de nuestra red y el ground truth que deberíamos predecir, la pérdida es:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vak4Fdg0s8f2"
      },
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "funcion_perdida = CrossEntropyLoss()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkR0nWLUDOrD",
        "outputId": "e6d0f5dd-c349-4acb-b870-287bc77c8cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "loss = funcion_perdida(output, target) # No correr este código, va a dar error! Es un ejemplo!"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-92613a9d6cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuncion_perdida\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# No correr este código, va a dar error! Es un ejemplo!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z61_pCzKDVPb"
      },
      "source": [
        "Súper, tenemos la pérdida, ¿cómo calculamos los gradientes?\n",
        "\n",
        "Para eso necesitamos un algoritmo de optimización. En el curso de Herramientas verán los algoritmos en detalle, pero les debería sonar Stochastic Gradient Descent (SGD), que es el algoritmo estándar de optimización. Este ya está implementado por el paquete torch.optim.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdfXdGgkEFXp",
        "outputId": "f027c47d-1242-491e-af7d-f11b1c191fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "optimizer = SGD(model.parameters())     # Vinculamos el recién creado optimizador\n",
        "                                        # a los parámetros de nuestro modelo"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-0f227d48bbb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Vinculamos el recién creado optimizador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                         \u001b[0;31m# a los parámetros de nuestro modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrequired\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 raise ValueError(\"parameter group didn't specify a value of required optimization parameter \" +\n\u001b[0;32m--> 238\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mparam_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: parameter group didn't specify a value of required optimization parameter lr"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRakjFJ1Ec8u"
      },
      "source": [
        "Esto por sí solo todavía no hace nada. El optimizador va a ir gestionando los gradientes que le llegan a cada parámetro de nuestro modelo. Actualizará los valores de los parámetros de acuerdo al algoritmo de optimización que implemente.\n",
        "\n",
        "Pero para gestionar gradientes tiene que sacarlos de alguna parte. ¡Esto lo hace backpropagation! Por suerte es muy fácil calcularlos en Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1SEJsy9FocF",
        "outputId": "122c71e4-ec67-49db-cdbf-7c17ca58226c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "loss.backward()                         # ¡Backpropagation! Eso es todo."
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-739fa9d2c2fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# ¡Backpropagation! Eso es todo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHc9IlalF1sb"
      },
      "source": [
        "Luego uniendo todas las piezas, en cada iteración de nuestro algoritmo de entrenamiento haremos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3CqYbbljsJC",
        "outputId": "5b67bd37-54c5-41b3-9cfa-8b4e321cb46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "optimizer.zero_grad()                   # 1. Hacemos cero los gradientes de los parámetros\n",
        "output = model(input)                   # 2. Propagamos los datos de entrada por nuestro modelo\n",
        "loss = funcion_perdida(output, target)  # 3. Cálculamos la pérdida\n",
        "loss.backward()                         # 4. ¡Backpropagation! Calculamos los gradientes \n",
        "                                        # para nuestros parámetros. ¡Los gradientes \n",
        "                                        # dejan de ser 0!\n",
        "optimizer.step()                        # 5. Actualizamos los parámetros de nuestro modelo"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-81620dfec96f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# 1. Hacemos cero los gradientes de los parámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# 2. Propagamos los datos de entrada por nuestro modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuncion_perdida\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 3. Cálculamos la pérdida\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# 4. ¡Backpropagation! Calculamos los gradientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                         \u001b[0;31m# para nuestros parámetros. ¡Los gradientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2lKeEmPkFxN"
      },
      "source": [
        "## Evaluación de Rendimiento\n",
        "\n",
        "¿Cómo evaluamos el rendimiento? En problemas de clasificación lo que usualmente haremos es comparar el ground truth respecto a lo que predecimos. ¿Qué es lo que predecimos? Usualmente será la clase de mayor valor en su salida entre las N clases que tenemos que predecir. Esto lo podemos hacer usando la función *argmax* de Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDF-5Ei0_Kkh",
        "outputId": "6a9689e7-4383-4de8-a1ad-ff4871001829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "output = model(input)                       # Tensor de salida de tamaño (batch_size, n_clases)\n",
        "preds = output.argmax(dim=1)                # Nos quedamos con el índice que tiene mayor valor\n",
        "                                            # entre las N clases.\n",
        "n_correctas = (preds == targets).sum()      # preds == targets entrega un tensor de 1s o 0s.\n",
        "total = targets.shape[0]                    # Total de ejemplos\n",
        "acc = n_correctas/total                     # Accuracy es correctas/total"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-566450761fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# Tensor de salida de tamaño (batch_size, n_clases)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# Nos quedamos con el índice que tiene mayor valor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             \u001b[0;31m# entre las N clases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_correctas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# preds == targets entrega un tensor de 1s o 0s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                    \u001b[0;31m# Total de ejemplos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-967282dcd922>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m                                  \u001b[0;31m# que conectar las piezas una detrás de la\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                                  \u001b[0;31m# otra. No todas las redes son así.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: conv2d(): argument 'input' (position 1) must be Tensor, not method"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNXwwivwjAKo"
      },
      "source": [
        "## Uniendo todo\n",
        "\n",
        "Vamos a unir todos estos componentes para armar un flujo de entrenamiento completo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZOhD3d40KXu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCdJwSCajFsr",
        "outputId": "4b965e05-ee12-4f86-e5ac-f25af6434a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos\n",
        "\n",
        "n_epochs = 20\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU/ target=objetivo que queremos predecir\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.46 Correctas: 159.0 Total: 5687.0 Accuracy: 2.80%\n",
            "Epoca 2: Loss: 4.38 Correctas: 214.0 Total: 5687.0 Accuracy: 3.76%\n",
            "Epoca 3: Loss: 4.01 Correctas: 359.0 Total: 5687.0 Accuracy: 6.31%\n",
            "Epoca 4: Loss: 3.98 Correctas: 455.0 Total: 5687.0 Accuracy: 8.00%\n",
            "Epoca 5: Loss: 3.72 Correctas: 539.0 Total: 5687.0 Accuracy: 9.48%\n",
            "Epoca 6: Loss: 3.51 Correctas: 687.0 Total: 5687.0 Accuracy: 12.08%\n",
            "Epoca 7: Loss: 3.64 Correctas: 820.0 Total: 5687.0 Accuracy: 14.42%\n",
            "Epoca 8: Loss: 3.22 Correctas: 1068.0 Total: 5687.0 Accuracy: 18.78%\n",
            "Epoca 9: Loss: 2.98 Correctas: 1206.0 Total: 5687.0 Accuracy: 21.21%\n",
            "Epoca 10: Loss: 2.73 Correctas: 1403.0 Total: 5687.0 Accuracy: 24.67%\n",
            "Epoca 11: Loss: 2.69 Correctas: 1621.0 Total: 5687.0 Accuracy: 28.50%\n",
            "Epoca 12: Loss: 2.70 Correctas: 1820.0 Total: 5687.0 Accuracy: 32.00%\n",
            "Epoca 13: Loss: 2.34 Correctas: 2016.0 Total: 5687.0 Accuracy: 35.45%\n",
            "Epoca 14: Loss: 2.43 Correctas: 2286.0 Total: 5687.0 Accuracy: 40.20%\n",
            "Epoca 15: Loss: 2.04 Correctas: 2566.0 Total: 5687.0 Accuracy: 45.12%\n",
            "Epoca 16: Loss: 1.82 Correctas: 2827.0 Total: 5687.0 Accuracy: 49.71%\n",
            "Epoca 17: Loss: 1.63 Correctas: 3091.0 Total: 5687.0 Accuracy: 54.35%\n",
            "Epoca 18: Loss: 1.41 Correctas: 3414.0 Total: 5687.0 Accuracy: 60.03%\n",
            "Epoca 19: Loss: 1.35 Correctas: 3594.0 Total: 5687.0 Accuracy: 63.20%\n",
            "Epoca 20: Loss: 1.06 Correctas: 3964.0 Total: 5687.0 Accuracy: 69.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmpMxT9_ypG"
      },
      "source": [
        "### Evaluando el modelo en el conjunto de Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXaeSaTV-KzJ",
        "outputId": "8eb25924-3942-4fef-ad46-13e47dbec700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.94 Correctas: 673.0 Total: 1738.0 Accuracy: 38.72%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Hrw55cmD-d"
      },
      "source": [
        "## Guardar el Modelo\n",
        "\n",
        "Una vez entrenado, querremos guardar el modelo para no tener que reentrenarlo cada vez que lo queramos usar. Esto es fácil de hacer en Pytorch. Hay dos formas de hacerlo:\n",
        "\n",
        "* La forma bruta es guardar el objeto completo usando torch.save. Esto guarda todo el objeto a disco. Por lo tanto ocupa más espacio. Pero este no es el mayor problema, sino que el modelo queda vinculado al computador en que se creó. Algo nada apetecible si queremos correr el modelo entrenado en otra máquina. Si se desea proseguir, se hace de la siguiente manera:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTj1Wvg_mYlI"
      },
      "source": [
        "torch.save(model, \"modelo_entrenado.pth\")\n",
        "\n",
        "modelo = torch.load(\"modelo_entrenado.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjKpS6ndmd2d"
      },
      "source": [
        "* La forma más eficiente y correcta es simplemente guardar los pesos. Estos se encuentran en una estructura llamada *'state_dict'* en el modelo. Una vez guardados, para recuperar nuestro modelo, tenemos que crear un modelo nuevo y ocupar el método *'load_state_dict'* para cargar los pesos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2NceHcCmd_E",
        "outputId": "42edf4ac-2fb0-4211-d2a6-d6605e1ddf60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.save(model.state_dict(), \"pesos_modelo_entrenado.pth\") # Guardamos a disco los pesos\n",
        "\n",
        "modelo = MiAlexNet()                                # Modelo con pesos aleatorios\n",
        "pesos = torch.load(\"pesos_modelo_entrenado.pth\") # Cargamos los pesos a una variable\n",
        "modelo.load_state_dict(pesos)                       # ¡Los pesos se encuentran \n",
        "                                                    # cargados en el modelo!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgIRqm5YaL6"
      },
      "source": [
        "## Actividades\n",
        "\n",
        "1. Entrene el modelo MiAlexNet por 10 épocas. ¿Qué resultados obtiene en train y test?\n",
        "2. Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. Entrénelo por 10 épocas. ¿Ve cambios en el rendimiento del modelo?\n",
        "3. Agregue capas de Batch Normalization (*BatchNorm2d*) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 épocas. ¿Ve algún cambio en el entrenamiento?\n",
        "4. Ocupe el modelo preentrenado en ImageNet de AlexNet. Entrénelo por 10 épocas. ¿Afecta en algo en rendimiento? Para ocupar el modelo preentrenado reemplace esta línea del código de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPXbZ7F6rpYH"
      },
      "source": [
        "model = MiAlexNet()     # Creamos el modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJPwrpZOrpfL"
      },
      "source": [
        "Por esta otra línea:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjA6rheBq3YC"
      },
      "source": [
        "from torchvision.models import alexnet\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "model.features.requires_grad_(False)\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 102),\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Q3BQkaer6E"
      },
      "source": [
        "### Respuestas Actividad\n",
        "\n",
        "Por favor, sus respuestas a la actividad acá. No modificar el código anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APuyXZZteWZw"
      },
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "#**Actividad 1**\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nae9GUxJKK-z"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgL5q4ogMRWM"
      },
      "source": [
        "<br>\n",
        "\n",
        "**Entrenamos:**\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9OnSDXeeWhF",
        "outputId": "2b061b3c-545d-470f-a39d-e09c79b2df21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU/ target=objetivo que queremos predecir\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.47 Correctas: 165.0 Total: 5687.0 Accuracy: 2.90%\n",
            "Epoca 2: Loss: 4.27 Correctas: 221.0 Total: 5687.0 Accuracy: 3.89%\n",
            "Epoca 3: Loss: 3.98 Correctas: 341.0 Total: 5687.0 Accuracy: 6.00%\n",
            "Epoca 4: Loss: 4.00 Correctas: 397.0 Total: 5687.0 Accuracy: 6.98%\n",
            "Epoca 5: Loss: 3.66 Correctas: 473.0 Total: 5687.0 Accuracy: 8.32%\n",
            "Epoca 6: Loss: 3.33 Correctas: 583.0 Total: 5687.0 Accuracy: 10.25%\n",
            "Epoca 7: Loss: 3.50 Correctas: 795.0 Total: 5687.0 Accuracy: 13.98%\n",
            "Epoca 8: Loss: 3.42 Correctas: 957.0 Total: 5687.0 Accuracy: 16.83%\n",
            "Epoca 9: Loss: 3.19 Correctas: 1084.0 Total: 5687.0 Accuracy: 19.06%\n",
            "Epoca 10: Loss: 3.10 Correctas: 1293.0 Total: 5687.0 Accuracy: 22.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiI7mSW-MYil"
      },
      "source": [
        "<br>\n",
        "\n",
        "**Evaluamos:**\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDATEutbBpF1",
        "outputId": "63e4d61a-4eda-46e7-f65f-64348ac687e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 3.14 Correctas: 346.0 Total: 1738.0 Accuracy: 19.91%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAybqpHZN0SL"
      },
      "source": [
        "Después de la decima y ultima epoca, nuestra red MiAlexNet obtiene una precisión de 19.91%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVzxMB2JeWpn"
      },
      "source": [
        "<br>\n",
        "\n",
        "#**Actividad 2**\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srgh6pxteWvE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        self.drop = nn.Dropout(p=0.15)\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(0.1),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        \n",
        "        self.drop2 = nn.Dropout(p=0.25)\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential( #nn.Dropout(0.2),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.drop2(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxHPfnVnFbAu",
        "outputId": "134d1e28-764e-4515-9a38-09184ae78cb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU/ target=objetivo que queremos predecir\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 4.50 Correctas: 143.0 Total: 5687.0 Accuracy: 2.51%\n",
            "Epoca 2: Loss: 4.23 Correctas: 296.0 Total: 5687.0 Accuracy: 5.20%\n",
            "Epoca 3: Loss: 3.97 Correctas: 380.0 Total: 5687.0 Accuracy: 6.68%\n",
            "Epoca 4: Loss: 3.71 Correctas: 477.0 Total: 5687.0 Accuracy: 8.39%\n",
            "Epoca 5: Loss: 3.57 Correctas: 652.0 Total: 5687.0 Accuracy: 11.46%\n",
            "Epoca 6: Loss: 3.30 Correctas: 804.0 Total: 5687.0 Accuracy: 14.14%\n",
            "Epoca 7: Loss: 3.17 Correctas: 961.0 Total: 5687.0 Accuracy: 16.90%\n",
            "Epoca 8: Loss: 3.34 Correctas: 1189.0 Total: 5687.0 Accuracy: 20.91%\n",
            "Epoca 9: Loss: 2.56 Correctas: 1273.0 Total: 5687.0 Accuracy: 22.38%\n",
            "Epoca 10: Loss: 2.93 Correctas: 1543.0 Total: 5687.0 Accuracy: 27.13%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V3muBp6KPXO"
      },
      "source": [
        "<br>\n",
        "\n",
        "**Ahora evaluamos su rendimiento:**\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEAzRKQmFf6t",
        "outputId": "c119dbdb-fa8a-46c0-ebb2-001a837ba7bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.87 Correctas: 449.0 Total: 1738.0 Accuracy: 25.83%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UAPyvGMec8I"
      },
      "source": [
        "Podemos sacar en conclusión que a medida que nuestras arquitecturas de red se vuelven más profundas y complejas, debemos considerar la posibilidad de aplicar Dropout para reducir las posibilidades de overfitting de nuestra red.\n",
        "\n",
        "Cuando evaluamos la arquitectura en el conjunto de datos sin Dropout, se obtuvo una precisión del 19.91%. Ademas existe la posibilidad de un sobreajuste.\n",
        "\n",
        "Sin embargo, cuando se utilizó MiAlexNet con Dropout, la precisión aumentó al 25.83%. Entonces, a medida que nuestra arquitecturas de red se vuelve más profunda, podemos aprender más características discriminatorias. Pero también debemos tener especial cuidado y asegurarnos de que nuestra red no se adapte demasiado ya que de lo contrario, la precisión caerá. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDIv-92OeW7W"
      },
      "source": [
        "<br>\n",
        "\n",
        "#**Actividad 3**\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWG63UwfFokN"
      },
      "source": [
        "Primero editamos el codigo de la clase MiAlexNet() para agregar las capas de BN. Lo que hará Batch Normalization será agarrar un \"batch\" o un subconjunto del set de entrenamiento(conjunto de vectores), y forzará que cada una de las dimensiones de ese batch sea media cero y varianza igual a 1. \n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz27SKTHeXCq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(MiAlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=2),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=2),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "\n",
        "        self.conv2_bn = nn.BatchNorm2d(256) #Primera capa BatchNorm\n",
        "\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "\n",
        "        self.conv3_bn = nn.BatchNorm2d(384)\n",
        "        \n",
        "          #Segunda capa BatchNorm\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=1),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "\n",
        "        self.conv4_bn = nn.BatchNorm2d(384) #Tercera capa BatchNorm\n",
        "        \n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=1),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 102)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x) \n",
        "        x = self.conv2_bn(x)  \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv3_bn(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv4_bn(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgsJQ7KDKiGO"
      },
      "source": [
        "<br>\n",
        "\n",
        "**Entrenamos:**\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Ma_qCuesxm",
        "outputId": "33c1d763-2878-415a-c228-2d23f0124b28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "model = MiAlexNet()     # Creamos el modelo\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU/ target=objetivo que queremos predecir\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoca 1: Loss: 3.61 Correctas: 266.0 Total: 5687.0 Accuracy: 4.68%\n",
            "Epoca 2: Loss: 3.27 Correctas: 805.0 Total: 5687.0 Accuracy: 14.16%\n",
            "Epoca 3: Loss: 3.31 Correctas: 1091.0 Total: 5687.0 Accuracy: 19.18%\n",
            "Epoca 4: Loss: 2.81 Correctas: 1333.0 Total: 5687.0 Accuracy: 23.44%\n",
            "Epoca 5: Loss: 3.04 Correctas: 1558.0 Total: 5687.0 Accuracy: 27.40%\n",
            "Epoca 6: Loss: 2.43 Correctas: 1772.0 Total: 5687.0 Accuracy: 31.16%\n",
            "Epoca 7: Loss: 2.31 Correctas: 2042.0 Total: 5687.0 Accuracy: 35.91%\n",
            "Epoca 8: Loss: 2.32 Correctas: 2350.0 Total: 5687.0 Accuracy: 41.32%\n",
            "Epoca 9: Loss: 2.14 Correctas: 2497.0 Total: 5687.0 Accuracy: 43.91%\n",
            "Epoca 10: Loss: 2.02 Correctas: 2718.0 Total: 5687.0 Accuracy: 47.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpF9t990KnGQ"
      },
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "**Evaluamos:**\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evdeNLnpFFfA",
        "outputId": "fa0fdc4b-704d-4588-bb11-d332ce310907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.64 Correctas: 677.0 Total: 1738.0 Accuracy: 38.95%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT7avLL-GxzR"
      },
      "source": [
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Si bien cada época puede llevar más tiempo, se ve que podemos reducir la cantidad total de épocas necesarias para entrenar las redes y obtener un entrenamiento más estable con menos ajuste de hiperparámetros. \n",
        "\n",
        "Por lo tanto, la conclusión aquí es que:\n",
        "<br>\n",
        "\n",
        "La normalización por lotes puede conducir a una convergencia más rápida y estable con mayor precisión. Sin embargo, las ventajas vendrán a expensas del tiempo de capacitación: la normalización de lotes\n",
        "requieren más \"wall time\" para entrenar la red, aunque la red obtendrá más\n",
        "precisión en menos épocas.\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3esj4ZFEeX3w"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "#**Actividad 4**\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMb0lgVdeX9R",
        "outputId": "39511f64-a3b7-4fff-ba63-ff7a91d08715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "f031867453d849cd8a88412b654d0c83",
            "1b72c330a9854fd49d82b375b397ea07",
            "8f312cf707c74f8fa1e20085828dcdfb",
            "5d965411381043edbd8f29d2cde15d40",
            "14f67981ba984b5796eef827ca84ff6a",
            "25b5504a0fb04dd39d736417253cd4f9",
            "8de1c122dc844a06a45a2c15651e3894",
            "985cf20380874b2e8a5606e2e8f4f8f6"
          ]
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "model.features.requires_grad_(False)\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 102),\n",
        "        )\n",
        "\n",
        "model = model.cuda()    # Lo enviamos para que se ejecute en GPU\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\n",
        "ds_train = Flowers(\"flowers_dataset/train\", transform=transforms) # Creamos\n",
        "\n",
        "n_epochs = 10\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\n",
        "loss_function = CrossEntropyLoss()      # Creamos la función de pérdida\n",
        "\n",
        "\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    \n",
        "    total_correctas = 0.0\n",
        "    total_muestras = 0.0\n",
        "\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\n",
        "        # Inicio de la iteración\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU/ target=objetivo que queremos predecir\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "        loss.backward()                          # Backpropagation\n",
        "        optimizer.step()                         # Actualizamos parámetros\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(epoch,\n",
        "                                                                                      loss,\n",
        "                                                                                      total_correctas, \n",
        "                                                                                      total_muestras,\n",
        "                                                                                      100*accuracy), end=\"\")\n",
        "    print(\"\")     "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f031867453d849cd8a88412b654d0c83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoca 1: Loss: 2.29 Correctas: 1199.0 Total: 5687.0 Accuracy: 21.08%\n",
            "Epoca 2: Loss: 1.76 Correctas: 2963.0 Total: 5687.0 Accuracy: 52.10%\n",
            "Epoca 3: Loss: 0.84 Correctas: 3629.0 Total: 5687.0 Accuracy: 63.81%\n",
            "Epoca 4: Loss: 0.82 Correctas: 4054.0 Total: 5687.0 Accuracy: 71.29%\n",
            "Epoca 5: Loss: 1.01 Correctas: 4192.0 Total: 5687.0 Accuracy: 73.71%\n",
            "Epoca 6: Loss: 0.65 Correctas: 4412.0 Total: 5687.0 Accuracy: 77.58%\n",
            "Epoca 7: Loss: 1.07 Correctas: 4599.0 Total: 5687.0 Accuracy: 80.87%\n",
            "Epoca 8: Loss: 0.56 Correctas: 4669.0 Total: 5687.0 Accuracy: 82.10%\n",
            "Epoca 9: Loss: 0.56 Correctas: 4773.0 Total: 5687.0 Accuracy: 83.93%\n",
            "Epoca 10: Loss: 0.41 Correctas: 4810.0 Total: 5687.0 Accuracy: 84.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3LLsu3KI_HD",
        "outputId": "67030968-ed9d-435a-c071-2e2fd4266e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import alexnet\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\n",
        "\n",
        "total_correctas = 0.0\n",
        "total_muestras = 0.0\n",
        "\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\n",
        "    # Inicio de la iteración\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\n",
        "                                        # en el código de más abajo.\n",
        "        x = x.cuda()\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\n",
        "\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\n",
        "\n",
        "        preds = output.argmax(dim=1)             # El máximo valor es nuestra predicción\n",
        "        correctas = (preds == target).sum()      # Acumulamos las correctas durante la época\n",
        "        total_correctas += correctas               \n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\n",
        "\n",
        "        accuracy = total_correctas/total_muestras # Acc = correctas/total\n",
        "\n",
        "        print(\"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\".format(loss,\n",
        "                                                                                total_correctas, \n",
        "                                                                                total_muestras,\n",
        "                                                                                100*accuracy), end=\"\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.76 Correctas: 1377.0 Total: 1738.0 Accuracy: 79.23%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS1Du1aUmnQ8"
      },
      "source": [
        "Obtuvimos una precisión del 79,23%, sustancialmente más alta que la precisión anterior del 38.95% de MiAlexNet con BN. \n",
        "\n",
        "<br>\n",
        "\n",
        "Entre las conclusiones a sacar esta que:\n",
        "\n",
        "Antes de realizar la tarea computacionalmente costosa de entrenar nuestra red, primero hay que obtener una precisión de referencia en el conjunto de datos utilizando una red previamente entrenada.\n",
        "\n",
        "El uso de una red previamente capacitada como AlexNet requiere menos trabajo y podemos obtener una precisión de referencia en el conjunto de datos. Esta precisión de referencia nos podría ayudar a guiarnos. \n",
        "\n",
        "Finalmente, cuando entrenemos nuestras arquitecturas de red personalizadas, hay que asegúrarse de insertar capas de normalización por lotes, ya que si bien cada época puede llevar más tiempo, normalmente podrá reducir la cantidad total de épocas necesarias para entrenar la red y obtener un entrenamiento más estable con menos ajuste de hiperparámetros. \n",
        "Tambien a medida que nuestras arquitecturas de red se vuelven más profundas y complejas, debemos considerar la posibilidad de aplicar Dropout para reducir las posibilidades de sobreajuste de nuestra red.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ooKpo8Lwvf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}