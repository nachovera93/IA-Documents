{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grafos de computo.ipynb",
      "provenance": [],
      "mount_file_id": "1mXajH96G8TbhIo1lnxeqElqhmh_iBw6f",
      "authorship_tag": "ABX9TyNhhP2uDSTTByiDjTn9HSNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/Grafos_de_computo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BuRrI0q8q5J"
      },
      "source": [
        "#**Grafos de computo**\n",
        "\n",
        "\n",
        "Esta metodologia nos permitirá estructurar el modelo, la metodologia, el mecanismo y algoritmo de aprendizaje para poder hacerlo escalable y además nos permitira hacer la actualización de los pesos de las redes.\n",
        "Implementaremos un algoritmo de backpropagation\n",
        "\n",
        "<br>\n",
        "\n",
        "![Artificial Neural Network](https://www.bogotobogo.com/python/scikit-learn/images/NeuralNetwork1/NN-with-components-w11-etc.png)\n",
        "\n",
        "\n",
        "###**Que define a una red neuronal?**\n",
        "\n",
        "* Estructura: Numero de capas, numero de neuronas por capa.\n",
        "* La metodologia de calcular pesos $W_ij$, que conecta cada neurona *i* con la  neurona *j*. \n",
        "* La función de activación que modulará la señal que se enviá de una neurona a otra.\n",
        "\n",
        "<br>\n",
        "\n",
        "Los pesos que tendrá la red neuronal establecerá la relación entre la salida y la entrada, por lo que se debe encontrar una cantidad de pesos que caracterizarán el modelo y lograrán el mapeado deseado.\n",
        "\n",
        "<br>\n",
        "\n",
        "###**Perceptrón**\n",
        "\n",
        "<br>\n",
        "\n",
        "![Perceptrón](https://pythonmachinelearning.pro/wp-content/uploads/2017/09/Single-Perceptron.png.webp)\n",
        "\n",
        "* Es la unidad fundamental de una red neuronal.\n",
        "\n",
        "<br>\n",
        "\n",
        "####**Que debo hacer para que el perceptrón aprenda?**\n",
        "\n",
        "Para que el percetrón pueda aprender esa relacion entre la entrada y la salida será fundamentalmente modificar los pesos y asi encontrar un conjunto de pesos tal que establezca esta relación. Por lo tanto entrenar corresponderá a encontrar el mejor conjunto de pesos que establezca una relación entre la salida y la entrada.\n",
        "\n",
        "###**Como podemos entrenar el Perceptrón?**\n",
        "\n",
        "<br>\n",
        "\n",
        "* Como podemos elegir una buena funcion de objetivo?\n",
        "\n",
        "> Esto quiere decir, de que forma podriamos encontrar un criterio de aprendizaje que nos informe como mover estos pesos para encontrar el objetivo final?\n",
        "Para elegir una buena funcion objetivo se deberá encontrar una expresión matematica que cuantifique el error.\n",
        "\n",
        "![Error](https://d3i71xaburhd42.cloudfront.net/a6a3cdee2fa0ddbe3e88b3be2662a06fb2a38304/75-Figure3.12-1.png)\n",
        "\n",
        "<br>\n",
        "\n",
        "Que es el error? será el valor actual que esta botando a la salida comparada con el valor que yo deseo.\n",
        "Por lo que yo debo encontrar el valor mas pequeño de este.\n",
        "\n",
        "\n",
        "* Que caracteristicas debe tener la funcion objetivo?\n",
        "\n",
        "> Que sea convexa ya que eso me garantizará que podre ir moviendome a través de ella hasta encontrar el minimo error.\n",
        "\n",
        "* Que algoritmo de optimización podemos usar para resolver este problema?\n",
        "\n",
        "> El SGD ( Gradiente de descenso estocastico)\n",
        "\n",
        "\n",
        "\n",
        "**Por lo que los pasos de nuestro entrenamiento serán: Forward, Backward and Weights Update.** \n",
        "\n",
        "* Que significa esto?:\n",
        "> Primero tomar por ejemplo una imagen, hacer el paso de forward (pasarla por la red y obtener el resultado final)\n",
        "> Segundo paso será tomar este resultado y compararlo con lo que deberia ser y asi generar el error.\n",
        "> Con el error ya dado haremos el paso de backward, que tomará la cuatificación del error dada por la superficie de la imagen anterior y propagará estos valores de error por la red, por lo que si el valor del error es grande, este al propagarse hacia atrás modificara de gran forma el valor de los pesos.\n",
        "\n",
        "\n",
        "![image.png](https://www.simplilearn.com/ice9/free_resources_article_thumb/symbolic-representation-of-perceptron-learning-rule.jpg)\n",
        "\n",
        "<br>\n",
        "\n",
        "$$wi ← wi + ∆wi$$\n",
        "<br>\n",
        "$$∆wi = −η · \\frac{∂E\\vec{w}}{∂wi}\\ $$\n",
        "<br>\n",
        "$$E(\\vec{w}) = \\frac{1}{2} · (t_d - o_d)^2$$\n",
        "<br>\n",
        "$$\\frac{∂E(\\vec{w})}{∂wi} = -\\sum_{d∈D}(t_d - o_d) · o_d · (1 − o_d ) · x_i,_d\\$$ \n",
        "<br>\n",
        "\n",
        "−η = Learning rate, nos dirá con que intensidad se hará el movimiento del gradiente.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Para actualizar los pesos tendre un valor inicial $w_i$ que será el peso actual y le sumare $∆w_i$ y lo actualizaré.\n",
        "Este $w_i$ se basa en que tan fuerte es el gradiente, por lo que es igual al gradiente de la funcion de error que definimos con respecto al peso en cuestión.\n",
        "Entonces por cada iteracion el $∆w_i$ ira decreciendo.\n",
        "\n",
        "$t_d$ (target d) = corresponde a la salida esperada y $o_d$ corresponde a la salida real \n",
        "\n",
        "<br>\n",
        "\n",
        "Acomodamos un poco la ecuacion para trabajar con vectores, quedaría todo de la siguiente forma:\n",
        "\n",
        "$$\\vec{w} ← \\vec{w}+ ∆\\vec{w}$$\n",
        "<br>\n",
        "$$∆\\vec{w} = \\eta · \\nabla E(\\vec{w}) $$\n",
        "<br>\n",
        "$$\\nabla E(\\vec{w}) = [\\frac{∂E\\vec{w}}{∂w_0},\\frac{∂E\\vec{w}}{∂w_1},...,\\frac{∂E\\vec{w}}{∂w_n}]$$\n",
        "\n",
        "\n",
        "###**BackPropagation**\n",
        "\n",
        "Backpropagation nos permitirá ver cual es la responsabilidad de cada peso en el error de la red, y así veremos en que valor tenemos que variar cada peso para que la red cada vez aprendá más.\n",
        "\n",
        "* Esta basado en la regla de la cadena de forma recursiva.\n",
        "* Puede ser usado en redes de arbitrario tamaño.\n",
        "* Puede ser usado por cualquier tipo de red con funciónes diferenciables.\n",
        "* Pero no esta garantizado un buen rendimiento o llegar a un buen minimo local o global.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Calculo de errores](https://www.interactivechaos.com/sites/default/files/inline-images/tutorial_ml_096.png)\n",
        "\n",
        "<br>\n",
        "$$x_i · w(L-1) = a(L-1)$$ \n",
        "<br>\n",
        "$$E\\vec{w}= (y-(\\sum_{}w_i·x_i+b))^2$$\n",
        "<br>\n",
        "$$\\frac{∂E(\\vec{w})}{∂wi}=\\frac{∂(a\\vec{L})}\n",
        "{∂aL_-1}·\\frac{∂({aL_-1})}{∂(wL-1)}$$\n",
        "\n",
        "\n",
        "\n",
        "Esta imagen y ecuación nos muestra como el error se va propagando hacia atrás utilizando derivadas locales y multiplicaciones.\n",
        "\n",
        "<br>\n",
        "\n",
        "![activations](https://miro.medium.com/max/771/1*DcLWqOojI1b9jzQaLibUkQ.png)\n",
        "\n",
        "Aqui se lográ apreciar como la propragación del gradiente de la salida se va multiplicando con las derivadas locales para poder propagarlo, como se muestra en la imagen, en el paso de forward se calculan las derivadas locales y al hacer backpropagation estas se van multiplicando con este gradiente.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "###**Ejemplo:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![Pic](https://drive.google.com/uc?export=view&id=1GH5nNo9wfxJWzrhiWxwCggu3sdloXrMF)\n",
        "\n",
        "<br>\n",
        "\n",
        "En el grafo se muestra paso a paso el forward con el producto punto entre los pesos $$w_1,w_2,w_3$$ y los inputs: $$x_0, x_1$$ hasta obtener 0.73 aplicando la funcion de la sigmoide.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Pic2](https://drive.google.com/uc?export=view&id=1MFJdbiaRfV7hWcL2doRH8liYWuP36scu)\n",
        "\n",
        "<br>\n",
        "\n",
        "El siguiente paso es aplicar backpropagation, por lo que comenzamos con la derivada de la salida con respecto a la misma salida, por lo que nos da como resultado 1.\n",
        "<br>\n",
        "\n",
        "\n",
        "![Pic3](https://drive.google.com/uc?export=view&id=18stJ68n-yBbmvYABLTI7IlgiOqy6tKYD)\n",
        "\n",
        "<br>\n",
        " \n",
        "A continuación, los resultados paso a paso serían:\n",
        "\n",
        "$$\\frac{-1}{1.37^2} · (1.00) = -0.53 $$\n",
        "<br>\n",
        "\n",
        "En este caso, 1 toma el valor de la constante(c) por lo que la derivada final es 0+1=1 **( Verificar )**\n",
        "<br>\n",
        "$$(1)·(-0.53)=-0.53$$\n",
        "Siguiente propagación:\n",
        "<br>\n",
        "$$(e^{-1})(-0.53)=-0.20$$\n",
        "<br>\n",
        "Luego *a* vendría siendo -1, por lo tanto:\n",
        "$$(-1)·(-20)=0.20$$\n",
        "<br>\n",
        "En la ultima parte de la backpropagation se debe saber que la derivada local de cada suma es 1.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Pic4](https://drive.google.com/uc?export=view&id=1QG7W4625-Bz1V-uxpvD_bNcoaE334X9P)\n",
        "\n",
        "Para simplificar todo esto podemos utilizar la formula de la sigmoide, que al derivarla podemos ver que con reemplazar el valor que entra a la sigmoide nos dará como resultado la salida del backpropagation, siendo x la entrada.\n",
        "\n",
        "<br>\n",
        "\n",
        "##**Funciones de Activación**\n",
        "\n",
        "Son una forma de modular la señal de salida de una neurona\n",
        "\n",
        "<br>\n",
        "\n",
        "![Sigmoide](https://drive.google.com/uc?export=view&id=13XhtWW-6gYxRSu6fPWPz-qidflFTxkbO)\n",
        "\n",
        "* Propiedades buenas:\n",
        "> Suave y diferenciable\n",
        "> Empuja los valores de salida hacia los extremos, buena para la clasificación.\n",
        "\n",
        "Se puede sacar como conclusión al ver la imagen que esta funcion tomará valores cercanos a 1 si es que es muy positiva y valores cercanos a 0 si es que es muy negativa. En el caso de la funcion diferenciable, para valores grandes y pequeños el resultado es cero.\n",
        "\n",
        "<br>\n",
        "\n",
        "* Propiedades malas:\n",
        "> Neuronas saturadas(valor muy negativo o muy positivo) tienen gradiente cercano a cero por lo que la convergencia es muy lenta, \"aprenderia\" muy lentamente.\n",
        "> En Deep Learning causa desvanecimiento de gradiente. Este es un gran problema en redes neuronales recurrentes(RNNs), tiene como consecuencia que la red no \"aprenda\", ya que al ser un valor muy cercano a cero corta el proceso en que se va propagando el gradiente.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![Sigmoid](https://drive.google.com/uc?export=view&id=1ispCtkMgKF8sLWm0vTqH3rJl0u3HOCts)\n",
        "\n",
        "<br>\n",
        "\n",
        "Siendo L(Loss Function) y calculando su derivada parcial en función de los pesos, primero con respecto a la sigmoide, siguiendo la derivada de esta con respecto a z(argumento de la sigmoide) y finalmente el argumento con respecto al peso correspondiente.\n",
        "\n",
        "<br>\n",
        "\n",
        "![property](https://drive.google.com/uc?export=view&id=1DyR1RN7piJxGCHUVnRFF4YWTHoEjTvxM)\n",
        "\n",
        "* Como el valor de la sigmoide esta entre [0,1[, 1 restando la sigmoide y multiplicando esto po la sigmoide siempre nos dará positivo, por lo que la expresión queda definida por el signo de la derivada del error, si es negativa todos los pesos serán negativos, y si es contrario serán todos positivos.\n",
        "* Las salidas de la sigmoide no son centradas en cero\n",
        "* Por lo tanto todos los pesos del gradiente son positivos o negativos\n",
        "* Se produce el Efecto Zig-Zag: nunca podre tener resultados de mezclas entre positivos y negativos. Esto realentiza el proceso ya que no va directamente al objetivo.\n",
        "<br>\n",
        "\n",
        "![Zig-Zag](https://drive.google.com/uc?export=view&id=1W7VTK3hzY-R-jgMD8iT_hfjtY9B-drTq)\n",
        "<br>\n",
        "\n",
        "Para resolver estos problemas:\n",
        "\n",
        "<br>\n",
        "\n",
        "![Tanh](https://drive.google.com/uc?export=view&id=1XMeDcOc1oxx5AoYHwG098dYga8P9I_Fr)\n",
        "\n",
        "<br>\n",
        "\n",
        "Esta función esta centrada en cero, no se producirá el fenomeno de zig-zag \n",
        "<br>\n",
        "\n",
        "Malas Propiedades:\n",
        "* Las neuronas saturadas aún tienen gradientes cercanos a cero.\n",
        "* Convergencia lenta y desvanecimiento de gradiente.\n",
        "\n",
        "\n",
        "###**ReLU**\n",
        "\n",
        "![ReLU](https://drive.google.com/uc?export=view&id=1QUEgtN-m4MtMiqY5Y4SyGns_t1Hxzw7_)\n",
        "\n",
        "Esta función fundamentalmente entrega el valor de max entre 0 y el valor del argumento.\n",
        "\n",
        "Buenas Propiedades:\n",
        "* No tiene saturación en la parte positiva en el espacio de entrada.\n",
        "* Convergencia rapida con respecto a la funcion sigmoidea. Por lo que ya no tenemos el problema de perdida de aprendizaje o desvanecimiento del gradiente.\n",
        "* Puede ser hasta 10 veces mas rapida que una sigmoidal.\n",
        "* Computacionalmente eficiente\n",
        "\n",
        "<br>\n",
        "\n",
        "####**Ejemplo:**\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![ReLU vs Sigmoide](https://drive.google.com/uc?export=view&id=1ay4MDfOP3JvID0Rx-2OLDUt7teaYwqYy)\n",
        "\n",
        "<br>\n",
        "\n",
        "Linea punteada: Sigmoide tanh(x).\n",
        "Linea solida: ReLUs.\n",
        "\n",
        "Se demuestra en este paper que la ReLU logra un 25% de error de entrenamiento 6 veces mas rapido que la sigmoide o tanh.\n",
        "<br>\n",
        "\n",
        "Malas propiedades:\n",
        "* No diferenciable en cero, ya que no hay derivada en ese punto. Pero se puede arreglar mediante software.\n",
        "* Se satura con inputs negativos.\n",
        "* No es tan bueno para la clasificación, ya que la salida es continua y no tiene esa ventaja de la sigmoidea o tanh que tiene valores que pueden ser definidos como discretos.\n",
        "\n",
        "###**Leaky/Parametric Rectified Linear Unit**\n",
        "\n",
        "<br>\n",
        "\n",
        "![Leaky ReLU](https://drive.google.com/uc?export=view&id=1_WnFlCI8qpWKIflh7xm0_7kUT-d1GyS9)\n",
        "\n",
        "<br>\n",
        "Tiene una pequeña pendiente en la parte negativa\n",
        "\n",
        "Buenas propiedades:\n",
        "* No se satura (no mueren las neuronas)\n",
        "* Convergencia mas rapida que la función sigmoidal.\n",
        "* Computacionalmente eficiente.\n",
        "\n",
        "<br>\n",
        "\n",
        "Malas propiedades:\n",
        "* Mala para la clasificación, tiene valores continuos y no es facilmente discretizable.\n",
        "\n",
        "<br>\n",
        "\n",
        "###**ELU**\n",
        "\n",
        "<br>\n",
        "\n",
        "![ELU](https://drive.google.com/uc?export=view&id=1bkcxvdaFUsfop2QJ8PWGc6drqHbgrs2M)\n",
        "\n",
        "Tiene una exponencial en la parte negativa.\n",
        "\n",
        "<br>\n",
        "\n",
        "Buenas propiedades:\n",
        "* Todos los beneficios de las ReLUs y LReLUs.\n",
        "* El régimen de saturación negativo en comparación con la reLU agrega algo de robustez al ruido (el valor de desactivación es menos relevante) ya que aveces es necesario que cierto tipo de neuronas sean cero y por ende se desactiven.\n",
        "\n",
        "<br>\n",
        "Malas propiedades:\n",
        "* Requiere calcular e(x) y ya es computacionalmente mas costoso.\n",
        "\n",
        "<br>\n",
        "\n",
        "###**SoftMax**\n",
        "\n",
        "<br>\n",
        "\n",
        "![SoftMax](https://drive.google.com/uc?export=view&id=11rzkk1O2Nan2yRhZRHfezGOwiilwdBbT)\n",
        "\n",
        "<br>\n",
        "\n",
        "Como se logra apreciar en la imagen, al aplicar SoftMax a la salida de la red neuronal hacemos una normalizamos para obtener un valor basado en probabilidad. Las exponenciales causarán que penalizara los valores mas pequeños dejandolos aún mas abajo y los valores grandes crezcan mas, esto quiere decir que la normalizacion con exponenciales acentuará los valores mas probables.\n",
        "\n",
        "Buenas propiedades:\n",
        "* Es diferenciable\n",
        "* Acentua los valores mas grandes y penaliza los mas pequeños.\n",
        "\n",
        "<br>\n",
        "\n",
        "Generalmente podremos encontrar entre medio o en las capas ocultas de las redes neuronales funciones de la familia ReLU(ya que son rapidas) como primer aproach y despues hacer un ajuste mas preciso con SoftMax por ejemplo.\n",
        "\n",
        "<br>\n",
        "\n",
        "###**Inicialización de pesos**\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![Weights](https://drive.google.com/uc?export=view&id=1V-sSgoPX2tpd5rJqllbP6eAEyhFey8D3)\n",
        "\n",
        "<br>\n",
        "\n",
        "Con la inicialización de pesos podemos anticipar problemas como la explosión de la señal de entrada o el desvanecimiento del gradiente o de la señal de entrada.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Ejemplo:**\n",
        "\n",
        "<br>\n",
        "\n",
        "![Vanishing input signal](https://drive.google.com/uc?export=view&id=1oQlSXBz2Jg2bnqzUgDzuRn28RRQA7MgM)\n",
        " \n",
        " <br>\n",
        "\n",
        "Suponiendo una red como la mostrada en la imagen anterior, y sus matrices de peso con esos valores. Al elevar la matriz de pesos con su valor correspondiente, los valores inevitablemente irán descendiendo al ser elevados a una potencia muy grande, por lo que en algún lugar de la red se podría \"cortar\" el canal de comunicación.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Exploding input signal](https://drive.google.com/uc?export=view&id=1XqMzsctHr2MLrfDjcQslTlsCbCxb_y2u)\n",
        "\n",
        "<br>\n",
        "\n",
        "Caso contrario, ocurre al elegir valores como la imagen anterior ya que al elevarse a un numero muy grande explotaria.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Gradient Vanishing](https://drive.google.com/uc?export=view&id=1_0nu3OnFCh7Vhfuzg1ONhqRq8EBZxufj)\n",
        "\n",
        "Lo mismo ocurre en el caso del gradiente, al tomar ese valor de g(que sería de 1 al tomar su derivada con respecto a ese mismo punto),siendo los f'[x] las derivadas locales de cada nodo. \n",
        "Con valores menores a 1 el gradiente se va a desvanecer y se cortara el canal de comunicación\n",
        "\n",
        "<br>\n",
        "\n",
        "![Exploding Gradient](https://drive.google.com/uc?export=view&id=1zn-F3tTl1Wdx4TaPtNqSP-XKblXqgwLE)\n",
        "\n",
        "<br>\n",
        "\n",
        "Caso contrario, cuando es mayor a 1 habrá una explosión del gradiente y dará pasos gigantes para encontrar el minimo, lo que no es bueno.\n",
        "\n",
        "<br>\n",
        "\n",
        "* Entonces como inicializamos los pesos? Necesitamos que la señal fluya en ambas direcciones.\n",
        "\n",
        "> Debemos tratar de tener control en la relación entre las varianzas de los valores de los pesos de la entrada y salida de cada capa.\n",
        "\n",
        "<br>\n",
        "\n",
        "![1](https://drive.google.com/uc?export=view&id=1ttxWmHaKweurw73xz6BD5iJ12_tKt6us)\n",
        "\n",
        "<br>\n",
        "\n",
        "E(Xi)= La esperanza o valor esperado de Xi.\n",
        "Var(Wi)=Varianza de Wi.\n",
        "\n",
        "Como queremos controlar los pesos y las entradas, podemos asumir que el valor medio de estas varianzas aleatorias será 0. Por lo que nuestros 2 primeros terminos de la relación anterior se eliminarán, quedando la ecuación de mas abajo.\n",
        "Esta formula corresponde a un solo par de peso e input.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![2](https://drive.google.com/uc?export=view&id=1n0LVTHINKxG0rzYeVRE09oajGOu6z53O)\n",
        "\n",
        "<br>\n",
        "Fe de erratas en imagen: (W1*X1) \n",
        "\n",
        "<br>\n",
        "\n",
        "Ahora si queremos aplicar la varianza a todo el perceptrón, nuestra ecuación correspondera a que la varianza de nuestra salida será igual a la varianza del producto punto\n",
        "Entonces asumiendo que Xi y Wi, y por ende las varianzas son independientes y distribuidas identicamente nos da como resultado la expresión final de la imagen anterior. Con n igual al numero de terminos por la varianza de los pesos y entradas.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![3](https://drive.google.com/uc?export=view&id=11Jh9O0fMbjnwqnoCyicO9LzNp9qNrLtY)\n",
        "\n",
        "<br>\n",
        "\n",
        "Entonces, La varianza de la salida es la varianza de la entrada escalada por la varianza de los pesos y n.\n",
        "<br>\n",
        "\n",
        "Por lo que si queremos que la varianza de la salida Y sea igual a la varianza de la entrada Xi, n*Var(Wi) o varianza de los pesos, debe ser igual a 1. \n",
        "<br>\n",
        "\n",
        "Llegamos a una condición de inicialización de pesos que será la varianza de los pesos igual a 1 dividido en las n entradas a la neurona(fan_in) y contrario en el proceso de backpropagation será fan_out, estas 2 deben ser iguales para poder satisfacer las 2 limitaciones.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![4](https://drive.google.com/uc?export=view&id=1uK5W1bQBJRdRH81yJZCmr-0Xxt_jpkSR)\n",
        "\n",
        "<br>\n",
        "\n",
        "Tomando el promedio de las varianzas de pesos como se muestra en la imagen anterior lograremos una buena condición para inicializar los pesos. Esta inicialización de pesos se llama inicialización de Glorot, en el que se asume que la inicialización de los pesos será en forma de distribución gaussiana con media cero y varianza igual al promedio del fan_in y fan_out(numero de entradas y salidas).\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![5](https://drive.google.com/uc?export=view&id=1NOD7lNR7f-pOeK0we-df5jqJwv2ViG_G)\n",
        "\n",
        "<br>\n",
        "\n",
        "Estas son otras estrategias para diferentes funciones de activación.\n",
        "<br>\n",
        "\n",
        "**Conclusión:** \n",
        "<br>\n",
        "Podemos decir que la inicialización de pesos ayuda un montón para evitar desvanecimiento y exploción de gradiente, pero no es una solución definitiva.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwMMUeTeUa8l"
      },
      "source": [
        "\n",
        "[1]https://towardsdatascience.com/back-propagation-simplified-218430e21ad0\n",
        "[2]Diplomado PUC, C.Aspillaga, G.Sepulveda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCwEOA0Tmgiw"
      },
      "source": [
        "\n"
      ]
    }
  ]
}