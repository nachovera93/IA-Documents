{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPskapNR0enn4wJk6EBu1Ds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/AlexNet%20con%20PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3d29fr2P_5l"
      },
      "source": [
        "##**Implementación de una red neuronal (ALexNet) con libreria PyTorch**\n",
        "\n",
        "<br>\n",
        "\n",
        "![alt text](https://www.researchgate.net/profile/Sherif_Shehata2/publication/308880040/figure/fig3/AS:413548556636165@1475609067864/An-illustration-of-the-architecture-of-AlexNet-deep-convolutional-neural-network.png)\n",
        "*AlexNet(Krizhevsky et al.,2012)*\n",
        "\n",
        "* Describiendo esta red:\n",
        "\n",
        "> En el input se observa que ocupa filtros de 11x11(x3) y ocupará 96 de ellos. El primer Stride es de 4, osea que se aplicaran zancadas de 4 pixeles. Los siguientes serán de 1.\n",
        "> Solo hay max Pooling en las capas que se indica. Si es que hay, usa stride de 2 y kernel de 3x3.\n",
        "> Ya en la segunda convolución se ocuparán filtros de 5x5(x96)\n",
        "\n",
        "> El *padding* por capa es:\n",
        "\n",
        ">Capa | Padding\n",
        ">--- | ---\n",
        ">Conv1 | 2\n",
        ">Conv2 | 2\n",
        ">Conv3 | 1\n",
        ">Conv4 | 1\n",
        ">Conv5 | 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srihWPW4bbim"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xl8S2FhFFA6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn           #PyTorch y su módulo de Redes Neuronales\n",
        "\n",
        "class AlexNet(nn.Module):                   # Esta clase representa nuestro modelo\n",
        "\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\n",
        "        super(AlexNet, self).__init__()\n",
        "        # Bloques Convolucionales\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\n",
        "        # elementos: Convolución, Pooling y Activación.\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\n",
        "\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\n",
        "                      stride=(4,4),              # Stride\n",
        "                      padding=(2,2)\n",
        "                      ),                # Cuántos pixeles de padding\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\n",
        "            nn.ReLU()                            # Activación                            \n",
        "        )\n",
        "\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=96,            \n",
        "                      out_channels=256,         \n",
        "                      kernel_size=(5,5),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=(2,2)),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                                 \n",
        "        )\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=256,          \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=(1,1)),                \n",
        "            nn.ReLU()                                                     \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(                           \n",
        "                      in_channels=384,           \n",
        "                      out_channels=384,         \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),              \n",
        "                      padding=(1,1)),                \n",
        "            nn.ReLU()                                            \n",
        "        )\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(                          \n",
        "                      in_channels=384,           \n",
        "                      out_channels=256,       \n",
        "                      kernel_size=(3,3),         \n",
        "                      stride=(1,1),          \n",
        "                      padding=(1,1)),               \n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.ReLU()                                               \n",
        "        )\n",
        "        ##\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\n",
        "                                    # resultado convolucional con capas\n",
        "                                    # lineales.\n",
        "        # Bloques Fully Connected/MLP\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\n",
        "        self.fc6 = nn.Sequential(\n",
        "                                  nn.Linear(9216, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 4096\n",
        "        self.fc7 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 4096), \n",
        "                                  nn.ReLU()\n",
        "                                  )\n",
        "        # Input = 4096 Output = 1000\n",
        "        self.fc8 = nn.Sequential(\n",
        "                                  nn.Linear(4096, 1000)\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\n",
        "                                 # Esta red es sencilla pues solo tenemos\n",
        "                                 # que conectar las piezas una detrás de la\n",
        "                                 # otra. No todas las redes son así.                      \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)   \n",
        "        x = self.conv3(x) \n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flat(x) \n",
        "        x = self.fc6(x) \n",
        "        x = self.fc7(x)\n",
        "        x = self.fc8(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}