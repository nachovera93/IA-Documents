{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-Learning-Architectures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7tmonprwQ2LmoJZRIQyKa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/Deep_Learning_Architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPBaX_wUcLKa"
      },
      "source": [
        "##**Deep Learning Architectures**\n",
        "\n",
        "<br>\n",
        "\n",
        "![Arch](https://drive.google.com/uc?export=view&id=1FNPy1YYIw28A20bRBBYxUwAugzoQn0ax)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "###**VGG-19/19**\n",
        "\n",
        "<br>\n",
        "\n",
        "La mayoria de los cambios de esta arquitectura se basan en el Campo Receptivo  \n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![Receptive-Field](https://drive.google.com/uc?export=view&id=1MNYgPFLXvEYe9IdKt_gqoWnRfwgC9se_)\n",
        "\n",
        "<br>\n",
        "\n",
        "El campo receptivo se refiere a la parte del input que \n",
        "corresponde o que se uso para generar el valor del filtro. La capa 3 de neuronas esta construida por filtros de 3x3, pero tiene un campo receptivo de 5x5. Ya que contiene toda la información de la primera capa.\n",
        "\n",
        "<br>\n",
        "\n",
        "![2](https://drive.google.com/uc?export=view&id=1CvB_JSil-hW8FS9Cu9svcCuV31qIIbZ9)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "VGG Es parecida a AlexNet con diferencias como por ejemplo, todas las capas tienen max-pooling, y tiene filtros de solo 3x3. Y aqui esta la clave ya que la composición de los filtros de 3x3 tiene el mismo campo receptivo que los filtros más grandes pero usa menos parámetros \n",
        "* Una sola capa con un filtro de 5x5 tiene un campo receptivo de 5x5 y 25 parámetros \n",
        "* Dos capas apiladas con filtros de 3x3 tienen un campo receptivo de 5x5 y 18 parámetros (3x3x2) \n",
        "* Menos parámetros implican menos tiempo de predicción y menos sobreajuste\n",
        "\n",
        "<br>\n",
        "\n",
        "Aqui se muestran las diferentes configuraciones que se probarón con VGG. Desde 11 a 19 capas de pesos.\n",
        "\n",
        "<br>\n",
        "\n",
        "![3](https://drive.google.com/uc?export=view&id=1Vjfg3L6yakhe6HAmoVbud59KxuPdzGYM)\n",
        "\n",
        "<br>\n",
        "\n",
        "##**Inception**\n",
        "\n",
        "<br>\n",
        "\n",
        "* Detección multiescala.\n",
        "* Reduce el numero de parametros y operaciones.\n",
        "\n",
        "<br>\n",
        "\n",
        "![4](https://drive.google.com/uc?export=view&id=1NPeZ9YZxos5hKbJ0_w_tFwaNjGkDkxW4)\n",
        "\n",
        "<br>\n",
        "\n",
        "(a)Inception Module, naive version.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "> Los objetos en una imagen pueden ser de múltiples escalas \n",
        "* La información de objetos de baja escala se puede capturar con filtros pequeños \n",
        "* Los objetos de gran escala necesitan filtros más grandes (o redes más profundas, recuerde el campo receptivo) \n",
        "\n",
        "> Idea \n",
        "* Tener múltiples tamaños de filtro en la misma capa y concatenar sus resultados \n",
        "* Deje que la red aprenda qué filtros son más útiles\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![5](https://drive.google.com/uc?export=view&id=1tkYAJehvoXlHOzRXe5DPLTOd1Am-Y08t)\n",
        "\n",
        "<br>\n",
        "\n",
        "(b)Inception module(bottleneck) with dimesion reductions\n",
        "\n",
        "<br>\n",
        "\n",
        "Por que se usan filtros de 1x1 antes de los filtros de 3x3 y 5x5?\n",
        "Comparemos:\n",
        "\n",
        "* Input channels: 192\n",
        "* 32 filtros de 5x5\n",
        "* Weights: 192x5x5x32 = 153600\n",
        "\n",
        "<br>\n",
        "\n",
        "Ahora, usemos:\n",
        "\n",
        "* 16 filtros de 1x1\n",
        "* Weights: 192x1x1x16 + 16x5x5x32 = 15872\n",
        "\n",
        "<br>\n",
        "\n",
        "Esto es casi un 90% de reducción de parametros. Entonces, ¿Que es lo que la convolución de 1x1 hace?\n",
        "\n",
        "<br>\n",
        "\n",
        "* Proyecta las caracteristicas de la capa anterior dentró de unas mas densa, de una forma comprimida\n",
        "* Es el mismo concepto de embedding (representación vectorial)\n",
        "* Por lo que podremos hacer las redes mas profundas\n",
        "\n",
        "<br>\n",
        "\n",
        "![6](https://drive.google.com/uc?export=view&id=1lPc30zGqREs0vR7EcFZsUmSfM0zfzfDQ)\n",
        "\n",
        "<br>\n",
        "\n",
        "Observar cómo hay una capa de agrupación promedio entre la última capa convolucional y la capa lineal. Esto reduce en gran medida la cantidad de parámetros.\n",
        "\n",
        "* 7x7x1024x1000 vs 1x1x1024x1000\n",
        "\n",
        "<br>\n",
        "\n",
        "![7](https://drive.google.com/uc?export=view&id=1FcnaVmDHPCsVHTFBXTqipaQ0bSjMCOye)\n",
        "\n",
        "<br>\n",
        "\n",
        "Por que hay 3 capas de softmax? ya que las red neuronales profundas sufren de desvanecimiento del gradiente. 2 clasificadores auxiliares agregados en capas intermediarias ayudan a esto.\n",
        "\n",
        "<br>\n",
        "\n",
        "###**Resnet**\n",
        "\n",
        "<br>\n",
        "\n",
        "Una red de N+1 capas muestra debería ser al menos igual de buena que una de N. Si la capa adicional no es útil, la red debe aprender la función de identidad para esa capa.\n",
        "\n",
        "<br>\n",
        "\n",
        "Extra capas, realidad:\n",
        "\n",
        "<br>\n",
        "\n",
        "![8](https://drive.google.com/uc?export=view&id=1RBBRAwFOlpRS9F-ew33DyjBFQ4LYyrOI)\n",
        "\n",
        "<br>\n",
        "\n",
        "Entonces, para solucionar este problema se hizo lo siguiente:\n",
        "\n",
        "> Hipotesis\n",
        "* No todos los sistemas son similares.\n",
        "\n",
        "> Proposito\n",
        "* Digamos que H(x) será nuestro mapping deseado\n",
        "* Ahora definimos el mapping residual F(x) = H(x)-x, donde F(x) es una función que yo aprendo y x será nuestro input( por lo que si yo no quiero que al input no le pase nada, la función deb ser cero)\n",
        "* H(x) = F(x)+x\n",
        "* Aprender las asignaciones de residuos.\n",
        "Si el mapeo de identidad es la solución óptima, es más fácil hacer que los pesos vayan a 0.\n",
        "\n",
        "![9](https://drive.google.com/uc?export=view&id=1xdou1oK6repLCc9WQnMuzEhTIPUD8_EI)\n",
        "\n",
        "![10](https://drive.google.com/uc?export=view&id=1zGqFSYPZjmrz6cu8xvbFZ0XFsTXS_9vM)\n",
        "\n",
        "![11](https://drive.google.com/uc?export=view&id=1MQXJn335pGiL0eQIoId5b2pOr29aE9BP)\n",
        "\n",
        "<br>\n",
        "\n",
        "Resnet tiene Batch Normalization despúes de cada capa convolucional, y no contiene dropout.\n",
        "\n",
        "<br>\n",
        "\n",
        "Resultados de Resnet, a la derecha las redes con residual.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![12](https://drive.google.com/uc?export=view&id=1mU-9l7AwnQaL1rqQYqdl3nj0pjh4qvoA)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0NinJFRcExG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}