{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algoritmos_de_optimización.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaYJvpB++p2GAgj+/IzmLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/Algoritmos_de_optimizaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnbAmaSz75hh"
      },
      "source": [
        "#**Algoritmos de Optimización y Learning Rate**\n",
        "\n",
        "<br>\n",
        "\n",
        "Como nosotros podriamos encontrar los mejores pesos que nos ayuden a resolver el problema?\n",
        "\n",
        "<br>\n",
        "\n",
        "####**Optimización**\n",
        "\n",
        "* El objetivo de un algoritmo de optimización es entregar los pasos para minimizar la función de perdida, modificando los pesos del modelo. Estos algoritmos son iterativos, osea que dan pasos a un optimo.\n",
        "\n",
        "<br>\n",
        "\n",
        "> **Algoritmo Gradiente Descendente**\n",
        "* Que es el gradiente?\n",
        "  * La derivada nos entrega la pendiente de los pesos, mientras mas empinada(mayor el valor), mayor debe ser el cambio. El gradiente nos indica la dirección en la cual  tenemos que mover los pesos para acercarnos a un optimo.En GD por cada epoca se va dando un paso hacia la optimización.\n",
        "* Pasos pequeños o largos?\n",
        "\n",
        "> **Algoritmo SGD (Stochastic)** \n",
        "\n",
        "  > No buscamos un valor perfecto de nuestro gradiente sino que un aproximado. Aparte, si el dataset que tenemos es mu grande el GD puede ser muy lento, ya que por cada iteración debemos pasar por todo el dataset. El SGD crea un subconjunto de datos(batch), por lo que nos permite acelerar el proceso de convegencia. Con SGD hacemos un paso hacia la optimización por cada batch aleatorio que tengamos. Ej: si tenemos 100 batchs haremos 100 iteraciones por cada epoca.\n",
        "  <br>\n",
        "  Este tiene igualmente algunos problemas como\n",
        "  * Saddle points(Gradiente es cero)\n",
        "  * Distintos grupos de datos pueden tener diferentes gradientes\n",
        "  * Importancia del tamaño de los pasos que damos\n",
        "  \n",
        "* Momentum\n",
        " * Agrega la idea de velocidad e historia de como se ah movido el gradiente.\n",
        " * Suavizamos el valor del gradiente con los valores pasados.\n",
        "* Nesterov\n",
        " * Es una forma alternativa de ver el momentum, buscamos hacer la correción del momentum antes de encontrar el gradiente.\n",
        " * Seguimos la dirección dado el momentum que tenemos.\n",
        "* Learning Rate\n",
        "\n",
        "> **Alternativas a SGD**\n",
        "* AdaGrad(adaptative gradient)\n",
        " * Cada peso tiene su propio gradiente, que se comporta diferente en el tiempo, dependiendo del batch.\n",
        " * La idea de AdaGrad es tener un learning rate adaptativo por peso del modelo, pesar los pesos del modelo según su propia historia.\n",
        " * Es una especie de normalización de los gradientes, los gradientes muy pronunciados son reducidos y los muy bajos son acelerados.\n",
        " * El valor del Learning Rate tiende a cero en el tiempo y ese es un problema de este.\n",
        "* Adam\n",
        " * Se utiliza la idea de estimadores de momento de primer y segundo orden.\n",
        " * Es una combinación entre SGD con momentum y AdaGrad (escalamiento).\n",
        "\n",
        "\n",
        "> **¿Como adaptar el Learning Rate durante el entrenamiento?**\n",
        "\n",
        "* En base al número de epocas, cada cierta cantidad de épocas, reducir el valor del learning rate por un factor. Esto nos dará un poco mas de sensibilidad al encontrar el mejor minimo.\n",
        "\n",
        "![SGD](https://drive.google.com/uc?export=view&id=1z5--KiJgwIaE7hQNtnUnRDdIdavlu0SP)\n",
        "\n",
        "<br>\n",
        "\n",
        "![SGD](https://drive.google.com/uc?export=view&id=1VsP_OM28iNpEhlMZL8neiiITqpjlaQpB)\n",
        "\n",
        "* Utilizando el conjunto de validación, verificar si el valor de la función de perdida no baja en n épocas, reducir el valor del learning rate. Con el set de validación podemos ver hipoteticamente como nos iría en el set de test.\n",
        "* El decaimiento del Learning Rate se basa entonces en la cantidad de epocas y al valor de la función de perdida del set de validación.\n",
        "* Scheduler\n",
        "* Early Stopping\n",
        " * Si durante el entrenamiento vemos que el conjunto de validación está empeorando aunque adaptemos el Learning Rate debemos detenerlo, ya que nuestra generalización se esta arruinando.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**Conclusiones**\n",
        "\n",
        "* ¿Cual es el objetivo del Optimizador?\n",
        " * Mover los pesos en dirección que minimice la función de perdida\n",
        "\n",
        "* ¿Cual es la tarea del Learning Rate?\n",
        " * Adaptar el tamaño de los pasos de los gradientes\n",
        "\n",
        "* ¿Para que sirve el Early Stopping?\n",
        " * Para que el modelo sufra menos de Overfitting\n",
        "\n",
        "* ¿Que ventaja nos trae usar Momentum?\n",
        " * Incentiva el uso de la historia de los gradientes de batch anteriores. \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICqI1EDT7Yw6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}