{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA1_AP2_Practico_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/IA1_AP2_Practico_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHopPtVaNF1K"
      },
      "source": [
        "# **Diplomado IA: Inteligencia Artificial I - Parte 2**. <br> Práctico 1: Grafo cómputo, inicialización de pesos y funciones activación\n",
        "---\n",
        "---\n",
        "\n",
        "**Profesores:**\n",
        "- Carlos Aspillaga\n",
        "- Gabriel Sepúlveda\n",
        "\n",
        "**Ayudante:**\n",
        "- Andrés Carvallo\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIdAKAdELPSl"
      },
      "source": [
        "# **Instrucciones Generales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmhnKlt8Ns7A"
      },
      "source": [
        "El siguiente práctico se debe realizar de forma individual. El formato de entregar es el **archivo .ipynb con todas las celdas ejecutadas**. Las secciones donde se planteen preguntas de forma explícita, deben ser respondida en celdas de texto, y no se aceptará solo el _output_ de una celda de código como respuesta.\n",
        "\n",
        "**Nombre alumno:**\n",
        "\n",
        "El siguiente práctico cuanta con 3 secciones donde cada una contendrá 1 o más actividades a realizar. Algunas actividades correspondrán a escribir código y otras a responder preguntas. \n",
        "\n",
        "Antes de responder, se recomienda **fuertemente** revisar las secciones previas donde se desarrollan los ejemplos, dado que algunas de las actividades pueden ser completadas reutilizando el mismo código.\n",
        "\n",
        "**Fecha de entrega:** viernes 13 de noviembre de 2020, 23:59 hrs.\n",
        "\n",
        "---\n",
        "**IMPORTANTE:** habrá un bonus de 1 décima para todos aquellos alumnos/as que muestren buen orden en sus respuestas (esto aplica a legibilidad de código, buena redacción, formalidad, organización del jupyter notebook, seguimiento de instrucciones, etc). El criterio lo pondrá cada ayudante corrector. La nota máxima obtenible en el laboratorio es 7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEloa5uXLIPK"
      },
      "source": [
        "# **Índice**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGlX5q_pQYRa",
        "colab_type": "toc"
      },
      "source": [
        "**Diplomado IA: Inteligencia Artificial I - Parte 2.  Práctico 1: Grafo cómputo, inicialización de pesos y funciones activación**\n",
        "\n",
        "[Funciones de Activación](#scrollTo=kZWTbXiJ2qnE)\n",
        "\n",
        ">[Experimento 1: Explorando y visualizando las funciones de activación](#scrollTo=NO2-omLG25ZB)\n",
        "\n",
        ">>[Actividad 1.1](#scrollTo=g-Y2h_iAjBqi)\n",
        "\n",
        ">>[Actividad 1.2](#scrollTo=S_BhTrrQlLOt)\n",
        "\n",
        ">[Experimento 2: Evolución de parámetros según función de activación](#scrollTo=sVd8UUyy1OUy)\n",
        "\n",
        ">>[Actividad 1.3](#scrollTo=F6R9-xepUBxi)\n",
        "\n",
        ">>[Actividad 1.4](#scrollTo=1Rtsp7KYWDZv)\n",
        "\n",
        "[Grafos de Cómputo](#scrollTo=Y653wzAj2ZhO)\n",
        "\n",
        ">[Experimento 1: Construcción de grafo de cómputo para entrenamiento de perceptrón](#scrollTo=-WbabEUqkbId)\n",
        "\n",
        ">[Experimento 2: Construcción de grafo de cómputo de alto nivel](#scrollTo=_qm9c16LmhxR)\n",
        "\n",
        ">[Experimento 3: ¿ Cómo entrenar nuestro perceptrón en pytorch ?](#scrollTo=DVUgM5taN_R2)\n",
        "\n",
        ">[Actividades (opcional)](#scrollTo=19knwwdcZKo3)\n",
        "\n",
        ">>[Actividad 2.1](#scrollTo=oILMcIAhnP-C)\n",
        "\n",
        "[Inicialización de Pesos](#scrollTo=Gch1aN5l60Yo)\n",
        "\n",
        ">[Experimento 1: Inicialización con valor constante](#scrollTo=c4DPyT3m64-w)\n",
        "\n",
        ">>[Inicialización de pesos con valores menor a 1](#scrollTo=ZbxLQ3iZswW0)\n",
        "\n",
        ">>[Inicialización de pesos con valores mayor a 1](#scrollTo=4zzY7EAy8cV1)\n",
        "\n",
        ">[Actividades (opcional)](#scrollTo=aSZ6LkFc3z_D)\n",
        "\n",
        ">>[Actividad 3.1](#scrollTo=X7LBCq8zdQwP)\n",
        "\n",
        ">>[Actividad 3.2](#scrollTo=Mr6SxpSo77kn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWTbXiJ2qnE"
      },
      "source": [
        "# **Funciones de Activación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO2-omLG25ZB"
      },
      "source": [
        "## Experimento 1: Explorando y visualizando las funciones de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS1N724bjgxY"
      },
      "source": [
        "Para esta etapa, vamos a explorar una función de activación, ver que valores posibles puede retornar y que gradientes puede devolver. \n",
        "\n",
        "Primero vamos a definir una función de activacion, en este caso la `ReLU` (https://pytorch.org/docs/stable/nn.html#relu).\n",
        "\n",
        "**Pytorch tip 1:** Para utilizar las funcionalidades de pytorch, debemos como primer paso imporate el paquete torch mediate: *import torch*\n",
        "\n",
        "**Pytorch tip 2:** Para acceder a las funciones de activación, utilizaremos el módulo torch.nn. Las funciones de activación deberán ser instanciadas como un objeto de la clase en cuestión. Por ejemplo: *torch.nn.ReLU()*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wj20y8MxeYf"
      },
      "source": [
        "import torch\n",
        "\n",
        "activation_function = torch.nn.ReLU()\n",
        "\n",
        "print(activation_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yAkX12mj2Jm"
      },
      "source": [
        "Luego vamos a utilizar dicha funcion para ver cual es la salida ante un valor positivo, el 0 y uno negativo.\n",
        "\n",
        "**Pytorch tip:** Aquí es importante notar que utilizaremos un tipo de dato Tensor del framework pytorch. Como su nombre lo indica, este tipo de dato permite la creación y manejo de tensores, que son la unidad fundamental para el flujo de las operaciones matemáticas definidas en cualquier arquitectura. En el caso particular del ejemplo, crearemos tendores de 1 dimensión a partir de una lista de python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyiRt6N9gc-f"
      },
      "source": [
        "x = torch.Tensor([2])\n",
        "positivo = activation_function(x)\n",
        "print( 'Función evaluada en un valor positivo: %d' % (positivo))\n",
        "\n",
        "x = torch.Tensor([0])\n",
        "cero = activation_function(x)\n",
        "print( 'Función evaluada en el cero: %d' % (cero))\n",
        "\n",
        "x = torch.Tensor([-9])\n",
        "negativo = activation_function(x)\n",
        "print( 'Función evaluada en un valor negativo: %d' % (negativo))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVb0VsNHkW2z"
      },
      "source": [
        "Ahora vamos a graficar todos los valores posible que puede tomar un valor ente -10 y 10 cuando se le aplica una función de activación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEk5GUSygsHd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy\n",
        "\n",
        "X = []\n",
        "Fx = []\n",
        "\n",
        "# Recorremos todos los valores entre -10 a 10 con diferencia de 0.1 entre cada valor\n",
        "for x in numpy.arange(-10, 10, 0.1):\n",
        "    X.append(x)\n",
        "    x = torch.Tensor([x])\n",
        "    result = activation_function(x)\n",
        "    Fx.append(float(result)) # convert Tensor() to float(), and append it into list\n",
        "\n",
        "plt.scatter(X, Fx)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lUuwvU1kiBF"
      },
      "source": [
        "Ahora obtendremos el valor del gradiente (derivada) que devuelve la función de activación ReLU en su parte lineal. Para ello utilizaremos el método *backward* sobre el tensor de resultado (salida de ReLU), para iniciar la retro-propagación de los gradientes. El proceso de cálculo que hay detrás de este método, es el mismo analizado para el cálculo de gradientes mediante grafos de cómputo.\n",
        "\n",
        "**Pytorch tip:** Aquí introduciremos un nuevo tipo de dato llamado *Variable*. Esta clase es simplemente un *wrapper* para de la clase Tensor, que permite mantener en memoria los datos necesarios para el cálculo de los gradientes y la estructura del grafo de cómputo. Para ello, es necesario entregar como argumento el tensor a utilizar, y el parámetro *requires_grad* con valor True. Para efectos operativos, *Variable* se comporta exactamente igual que *Tensor*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvGh7RhVhjuJ"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "# Definimos el valor de entrada e indicamos que debe almacenar el gradiente\n",
        "x = Variable(torch.Tensor([2]), requires_grad=True)\n",
        "\n",
        "result = activation_function(x)\n",
        "\n",
        "# Aplicamos el paso \"backward\" para propagar los gradientes\n",
        "result.backward()\n",
        "\n",
        "print( 'Función:    %s' % (activation_function))\n",
        "print( 'Input:      %f' % (x))\n",
        "print( 'Output:     %f' % (result))\n",
        "print( 'Gradiente:  %f' % (x.grad))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buv0QZJFkzil"
      },
      "source": [
        "Finalmente vamos a graficar todos los gradientes calculados al ingresar valores entre -10 y 10, o en otras palabras, vamos a graficar la derivada de la función de activación para dicho rango."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10uJ1e-FyWI1",
        "cellView": "both"
      },
      "source": [
        "X = []\n",
        "gradiente = []\n",
        "\n",
        "# Recorremos todos los valores entre -10 a 10 con diferencia de 0.1 entre cada valor\n",
        "for x in numpy.arange(-10, 10, 0.1):\n",
        "    X.append(x)\n",
        "    x = Variable(torch.Tensor([x]), requires_grad=True)\n",
        "    result = activation_function(x)\n",
        "    result.backward()\n",
        "    gradiente.append(float(x.grad))\n",
        "    \n",
        "plt.scatter(X, gradiente)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Y2h_iAjBqi"
      },
      "source": [
        "### Actividad 1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf4WdQllabI6"
      },
      "source": [
        "En el siguiente link: https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity se presenta un conjunto de funciones de activacion. Utilice la función `Sigmoid` para:\n",
        "1. Confeccionar el gráfico de la función\n",
        "2. Confeccionar el gráfico de su derivada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2GXt3Wq8Ocw"
      },
      "source": [
        "# Código para confeccionar el gráfico de la función"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGej2Z3v34BO"
      },
      "source": [
        "# Código para confeccionar el gráfico de su derivada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_BhTrrQlLOt"
      },
      "source": [
        "### Actividad 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M0PO03iafNn"
      },
      "source": [
        "Responda la siguiente pregunta.\n",
        "\n",
        "**1** - Entre un modelo con función de activación ReLU y otro con función de activación Sigmoidal, ¿ Cual cree usted que aprendería más rápido ?. Justifique su respuesta apoyandose en los gráficos generados anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwX_mI8PmYwF"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA8stjcfZiTX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut4IuFRQpeay"
      },
      "source": [
        "Si quedaste con ganas de explorar otras funciones de activacion y visualizar sus derivadas. Recomendamos la siguiente página: https://dashee87.github.io/deep%20learning/visualising-activation-functions-in-neural-networks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVd8UUyy1OUy"
      },
      "source": [
        "## Experimento 2: Evolución de parámetros según función de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDJ3o5GZr5rU"
      },
      "source": [
        "En esta sección estudiaremos el efecto que tiene el uso de distintas funciones de activación sobre la evolución de los parámetros de una red neuronal durante su entrenamiento.\n",
        "\n",
        "Antes de comenzar, definiremos como objetivo de aprendizaje la función lógica *AND*. Esta función recibe como entrada dos argumentos binarios que definiremos como *x1* y *x2*, y entrega como salida un número binario según la siguiente tabla de verdad:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td align=\"center\"><b>x1</b></td>\n",
        "    <td align=\"center\"><b>x2</b></td>\n",
        "    <td align=\"center\"><b>AND(x1, x2)</b></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td align=\"center\">0</td>\n",
        "    <td align=\"center\">0</td>\n",
        "    <td align=\"center\">0</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td align=\"center\">0</td>\n",
        "    <td align=\"center\">1</td>\n",
        "    <td align=\"center\">0</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td align=\"center\">1</td>\n",
        "    <td align=\"center\">0</td>\n",
        "    <td align=\"center\">0</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td align=\"center\">1</td>\n",
        "    <td align=\"center\">1</td>\n",
        "    <td align=\"center\">1</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Según estas relaciones, a continuación se implementa la clase *AndGateDataset*. Esta se encargará de generar todas las combinaciones que definen a la función AND, las cuales serán usadas para entrenar un modelo de red neuronal.\n",
        "\n",
        "**Pytorch tip:** Aquí presentamos la clase *Dataset* de Pytorch, la cual usaremos como clase base para implementar nuestra clase que generará los datos (AndGateDataset). Para el correcto funcionamiento de la clase *Dataset*, se deben implementar dos métodos. El método *\\_\\_len\\_\\_* que retornará el número de elementos del dataset, y el método *\\_\\_getitem\\_\\_*, que permitirá acceder a los elementos a través del operador de *corchetes* y un índice. Por ejemplo: my_dataset[2]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOEhD1DV1OkT"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Generador de datos de entrenamiento\n",
        "class AndGateDataset( Dataset ):\n",
        "\n",
        "  def __init__( self, transform = None ):\n",
        "    self.dataset = np.array( [[0, 0, 0],\n",
        "                              [0, 1, 0],\n",
        "                              [1, 0, 0],\n",
        "                              [1, 1, 1]] )\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__( self ):\n",
        "    return len( self.dataset )\n",
        "\n",
        "  def __getitem__( self, idx ):\n",
        "    if torch.is_tensor( idx ):\n",
        "      idx = idx.tolist()\n",
        "    sample = {'input': self.dataset[idx, :2], 'target': np.array( [self.dataset[idx, 2]] )}\n",
        "    if self.transform:\n",
        "      sample = self.transform( sample )\n",
        "    return sample\n",
        "\n",
        "# Conversor de datos generados por dataset\n",
        "class ToTensor( object ):\n",
        "\n",
        "  def __call__( self, sample ):\n",
        "    input_, target_ = sample['input'].astype( np.float32 ), sample['target'].astype( np.float32 )\n",
        "    return {'input': torch.from_numpy( input_ ),\n",
        "            'target': torch.from_numpy( target_ ) }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozZCq_9Bw6Th"
      },
      "source": [
        "Para poder aprender las relaciones anteriores, se ha diseñado una red neuronal de dos capas como la que se muestra en la siguiente figura:\n",
        "\n",
        "<img src=\"https://i.imgur.com/ptVyhY2.png\"></img>\n",
        "\n",
        "A continuación se define la clase *AndGateModel*, la cual implementa esta estructura utilizando el framework *PyTorch*.\n",
        "\n",
        "**Pytorch tip 1:** Aquí introduciremos la clase *Module* de pytorch. Esta clase sirve de base para la implementación de nuestros modelos, y para su correcto funcionamiento, se debe implementar el método *forward* que será llamado cada vez que se quieran calcular las salidas de un modelo a partir de una determinada entrada. Una vez implementado forward, para ejecutarlo simplemente basta con entregar los datos al objeto que contiene el modelo mediante el operador *paréntesis*. Por ejemplo: mi_modelo( x ).\n",
        "\n",
        "Otro aspecto a tener en cuenta es que cada vez que instanciemos esta clase deberemos llamar antes al constructor de *Module*, y luego el nuestro. Para ello, utilizaremos siempre al inicio del método *\\_\\_init\\_\\_* la siguiente expresión: *super( AndGateModel, self ).\\_\\_init\\_\\_()*.\n",
        "\n",
        "**Pytorch tip 2:**  Aquí introduciremos la clase *Linear* de pytorch, que permite la creación de una capa *fully connected* tan solo especificando la dimensión de entrada, y el número de neuronas de salida. Por ejemplo, para crear una capa oculta que reciba un vector de 2 dimensiones y que posea 10 neuronas ( es decir, 10 salidas ), llamaremos a: *nn.Linear( 2, 10 )*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvH79Tpn8ncV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AndGateModel( nn.Module ):\n",
        "\n",
        "  def __init__( self, activation_function ):\n",
        "    super( AndGateModel, self ).__init__()\n",
        "    self.activation_function = activation_function\n",
        "    self.layer1 = nn.Linear( 2, 2 ) # Capa 1: 2 entradas y 2 salidas\n",
        "    self.layer2 = nn.Linear( 2, 1 ) # Capa 2: 2 entradas y 1 salida\n",
        "\n",
        "  def forward( self, x ):\n",
        "    x = self.activation_function( self.layer1( x ) )\n",
        "    x = self.activation_function( self.layer2( x ) )\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmpcAeP-VT9"
      },
      "source": [
        "La siguiente función implementa el loop de entrenamiento que se encargará de actualizar los parámetros de la red con el fin de ajustar el modelo a los datos entregados.\n",
        "Como el objetivo del presente experimento es analizar cómo evolucionan los parámetros de la red, ejecutaremos el loop por solo dos épocas, y almacenaremos el valor que van tomando los parámetros $w_{21}$ y $w_{22}$ (ver figura anterior) junto a sus respectivos gradientes en el proceso.\n",
        "\n",
        "En este punto, no es necesario analizar todavía el detalle de esta implementación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3TrthPE-9n5"
      },
      "source": [
        "def fit( model, criterion, optimizer, n_epochs = 2 ):\n",
        "  w1_t = list()\n",
        "  w2_t = list()\n",
        "  w1_grad_t = list()\n",
        "  w2_grad_t = list()\n",
        "  for epoch in range( n_epochs ):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    epoch_train_accu = 0\n",
        "    batch_per_epoch_train = len( logic_func_trainset )\n",
        "    for i_batch, sample_batched in enumerate( dataloader_train ):\n",
        "      input_batch = sample_batched['input'].to( device )\n",
        "      target_batch = sample_batched['target'].to( device )\n",
        "\n",
        "      prediction = model( input_batch ) # (batch_size, 1)\n",
        "\n",
        "      train_loss = criterion( prediction, target_batch )\n",
        "\n",
        "      accuracy = model_accuracy( prediction.cpu().detach().numpy(), target_batch.cpu().detach().numpy() )\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_train_loss += train_loss.item()\n",
        "      epoch_train_accu += accuracy\n",
        "\n",
        "      w1_grad_t.append( float( model.layer2.weight.grad[0,0] ) )\n",
        "      w2_grad_t.append( float( model.layer2.weight.grad[0,1] ) )\n",
        "      w1_t.append( float( model.layer2.weight[0,0] ) )\n",
        "      w2_t.append( float( model.layer2.weight[0,1] ) )\n",
        "\n",
        "    epoch_train_loss /= (i_batch+1)\n",
        "    epoch_train_accu /= (i_batch+1)\n",
        "    print( 'Epoch %d: train loss %f acc %f' % (epoch+1, epoch_train_loss, epoch_train_accu ) )\n",
        "\n",
        "  return np.array( w1_t ), np.array( w2_t ), np.array( w1_grad_t ), np.array( w2_grad_t )\n",
        "\n",
        "def model_accuracy( predicted, target, threshold = 0.5 ):\n",
        "  nb_eq = 0\n",
        "  for i in range( target.shape[0] ):\n",
        "    p = np.where( predicted[i] >= threshold, 1, 0 )\n",
        "    t = np.where( target[i] >= threshold, 1, 0 )\n",
        "    nb_eq += np.array_equal( p, t )\n",
        "  return nb_eq / float( target.shape[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQM9uYe6OKvk"
      },
      "source": [
        "Las siguientes funciones nos ayudarán a definir el formato de los gráficos que facilitarán el análisis de resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_nMhbREOKN2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pylab\n",
        "\n",
        "%matplotlib inline\n",
        "pylab.rcParams['figure.figsize']=10,8 # default: [6, 4]\n",
        "\n",
        "def plot_gradients( w1_grad_t, w2_grad_t ):\n",
        "  t = np.array( range( len(w1_grad_t) ) )\n",
        "  plt.plot( t, w1_grad_t, 'o', label=r'$\\frac{\\partial L}{\\partial w_1}$' )\n",
        "  plt.plot( t, w2_grad_t, 'o', label=r'$\\frac{\\partial L}{\\partial w_2}$' )\n",
        "  plt.plot( t, np.zeros( len(w1_grad_t) ), 'r' )\n",
        "  plt.title( 'Secuencia de gradientes obtenida en entrenamiento', fontsize=14 )\n",
        "  plt.xlabel( 'Paso de entrenamiento', fontsize=14 )\n",
        "  plt.ylabel( 'Gradiente', fontsize=14 )\n",
        "  plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=25)\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "def plot_weight_evolution( w1_t, w2_t ):\n",
        "  x_margin = abs( w1_t.max() - w1_t.min() )*0.1\n",
        "  y_margin = abs( w2_t.max() - w2_t.min() )*0.1\n",
        "  plt.xlim( (w1_t.min() - x_margin, w1_t.max() + x_margin) )\n",
        "  plt.ylim( (w2_t.min() - y_margin, w2_t.max() + y_margin) )\n",
        "  plt.plot( w1_t[0], w2_t[0], 'o', color='red' )\n",
        "  plt.quiver( w1_t[:-1], w2_t[:-1], w1_t[1:]-w1_t[:-1], w2_t[1:]-w2_t[:-1], scale_units='xy', angles='xy', scale=1, width=0.002, color='blue', headwidth=5, headlength=5 )\n",
        "  plt.title( 'Evolución de los pesos $w_1$ y $w_2$ durante entrenamiento', fontsize=14 )\n",
        "  plt.xlabel( '$w_1$', fontsize=20 )\n",
        "  plt.ylabel( '$w_2$', fontsize=20 )\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWwxDwbISGzJ"
      },
      "source": [
        "Finalmente, en la siguiente sección se utilizarán las funciones anteriormente definidas para llevar a cabo nuestro experimento.\n",
        "\n",
        "En este caso en particular, veremos la evolución de los parámetros $w_{21}$ y $w_{22}$ para una red con función de activación Sigmoidal.\n",
        "\n",
        "**Pytorch tip:** La función sigmoidal es implementada en *pytorch* por la siguiente clase: *torch.nn.Sigmoid()*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyjp6SJu9-RH"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n",
        "\n",
        "# Creación de Dataloader\n",
        "logic_func_trainset = AndGateDataset( transform = transforms.Compose( [ToTensor()] ) )\n",
        "dataloader_train = DataLoader( logic_func_trainset, batch_size = 1, shuffle = True, num_workers = 1 )\n",
        "\n",
        "# Creación de modelo\n",
        "model = AndGateModel( nn.Sigmoid() )\n",
        "model.to( device )\n",
        "\n",
        "# Creación de instancias para la función de pérdida y optimizador\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD( model.parameters(), lr = 0.01 )\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "w1_t, w2_t, w1_grad_t, w2_grad_t = fit( model, criterion, optimizer )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdJI4_zdTdRX"
      },
      "source": [
        "Durante el entrenamiento, se ha almacenado la evolución de los parámetros $w_{21}$ y $w_{22}$ (ver diagrama de la red) y los correspondientes gradientes.\n",
        "A continuación se grafica su evolución en el tiempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czlNZ_CnfqSo"
      },
      "source": [
        "plot_gradients( w1_grad_t, w2_grad_t )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2iXA0ruA_Mn"
      },
      "source": [
        "Otra forma de ver la evolución de estos parámetros, es graficándolos en un plano cuyos ejes son precisamente \n",
        ", como se muestra continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V8LVty6fsRL"
      },
      "source": [
        "plot_weight_evolution( w1_t, w2_t )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6R9-xepUBxi"
      },
      "source": [
        "### Actividad 1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XruG0UQwUN_O"
      },
      "source": [
        "Las figuras graficadas por el código anterior muestran: \n",
        "\n",
        "* Fig. 1: Los valores que toman los gradientes de la pérdida en las variables $w_1$ y $w_2$ para cada paso de entrenamiento\n",
        "\n",
        "* Fig. 2: La evolución conjunta de los los parámetros $w_1$ y $w_2$.\n",
        "\n",
        "Según estas gráficas, ¿ Qué podría concluir acerca del valor que toman ambos parámetros para la función sigmoidal ?, ¿ existe algún patrón característico en su evolución ?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBNpuD32WBje"
      },
      "source": [
        "Respuesta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rtsp7KYWDZv"
      },
      "source": [
        "### Actividad 1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdWYK74gWFyp"
      },
      "source": [
        "Repita el experimento anterior, pero esta vez utilizando la función de activación Tangente Hiperbólica: *nn.Tanh*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgb7ENd9YfVO"
      },
      "source": [
        "# Código para Tanh:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmguvLssarzY"
      },
      "source": [
        "Según estas gráficas, ¿ Qué podría concluir acerca del valor que toman ambos parámetros para la función tangente hiperbólica ?, ¿ existe algún patrón característico en su evolución ?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOuW2fBfas6j"
      },
      "source": [
        "Respuesta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y653wzAj2ZhO"
      },
      "source": [
        "# **Grafos de Cómputo**\n",
        "\n",
        "Al lo largo de esta sección implementaremos las estructuras de datos que nos permitirán calcular el valor del gradiente en cada neurona dentro de una red neuronal, y a través de estos valores, aplicar una actualización de los parámetros de la red. Este procedimiento es conocido como *Backpropagation*.\n",
        "\n",
        "Las estructuras de datos mencionadas representarán a cada una de las operaciones matemáticas aplicadas, y serán construidas a partir del grafo de cómputo que caracteriza la red."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WbabEUqkbId"
      },
      "source": [
        "## Experimento 1: Construcción de grafo de cómputo para entrenamiento de perceptrón"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaBHRZyi8iKq"
      },
      "source": [
        "Comenzaremos con un experimento sencillo en el cual implementaremos el grafo de cómputo de un perceptrón, como el que se muestra en la siguiente figura.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td>\n",
        "      <img src='https://imgur.com/AbVPpPQ.png'/>\n",
        "    </td>\n",
        "    <td>\n",
        "$\\LARGE s = \\sigma( x \\cdot w_{0} + y \\cdot w_{1} + w_{2} )$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$donde:$\n",
        "\n",
        "$\\LARGE \\sigma(x) = \\frac{1}{1+e^{-x}}$\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n7uNsUau9_V"
      },
      "source": [
        "Si queremos determinar cuales son los valores que deben tener los parámetros del perceptrón, tal que podamos obtener una salida deseada ($target$) frente a un determinado vector de entrada ($\\vec{x}$), debemos incorporar una función conocida como *Loss Function* (o en español, función de pérdida).\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <td align=\"center\"><b>Entrada</b><br>$\\vec{x}$</td>\n",
        "    <td align=\"center\"><b>Salida Ideal<br>target</b></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td align=\"center\">$\\vec{x}_{0}$</td>\n",
        "    <td align=\"center\">$t{0}$</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td align=\"center\">$\\vec{x}_{1}$</td>\n",
        "    <td align=\"center\">$t{1}$</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td align=\"center\">...</td>\n",
        "    <td align=\"center\">...</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td align=\"center\">$\\vec{x}_{0}$</td>\n",
        "    <td align=\"center\">$t{0}$</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "La *Loss Function* recibirá como entrada el valor de salida del perceptrón calculado a partir de una determinada entrada $\\vec{x}$ y el valor actual de los pesos. Por otro lado, esta función recibirá además el valor de la salida ideal que deseamos obtener para la entrada actual $\\vec{x}$, el cual llamaremos *target*. Con estos dos valores de entada, la *Loss function* calculará un valor de pérdida (o error) que indicará que tan *parecidas* o *cercanas* son la salida actual con el *target*.\n",
        "\n",
        "La siguiente figura muestra el grafo de cómputo correspondiente al perceptrón anterior, más la función que calculará el error (*loss*) entre su salida y el valor objetivo (target).\n",
        "\n",
        "**Grafo de Cómputo**\n",
        "\n",
        "<img src=\"https://imgur.com/XMZXsi1.png\" />\n",
        "\n",
        "En nuestro experimento, definiremos la *Loss Function* como el error medio cuadrático entre la salida *s* y el *target*, mediante la siguiente ecuación:\n",
        "\n",
        "$\\large Loss = \\frac{1}{2} \\cdot (s-target)^2$\n",
        "\n",
        "Si calculamos sus derivadas parciales obtenemos:\n",
        "\n",
        "$\\large \\frac{\\partial Loss}{\\partial s} = s-target$\n",
        "\n",
        "$\\large \\frac{\\partial Loss}{\\partial target} = -(s-target)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5dftHvuvWvM"
      },
      "source": [
        "Con el fin de demostrar a bajo nivel como se implementan los grafos de cómputo, en esta sección no utilizaremos pytorch. Sin embargo, para facilitar las operaciones vectoriales nos ayudaremos por la biblioteca *numpy*.\n",
        "\n",
        "Dado lo anterior, comenzaremos por importar *numpy* y asignandole el alias *np*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xU7lnGcwS-R"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ECLFJ3TwB-T"
      },
      "source": [
        "Como vimos en clases, los grafos de cómputo requieres almacenar los valores de gradiente calculados en el proceso de *Backward*. Para ello, crearemos una clase de nombre *Var* que nos permitirá manejar todas las variables dentro de la red. Esta variable tiene como atributos el valor actual (*value*) y el valor del gradiente (*grad*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqp1alkbpxca"
      },
      "source": [
        "class Var( object ):\n",
        "  def __init__(self, value, grad):\n",
        "    self.value = value\n",
        "    self.grad = grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DP5HyOQwvEi"
      },
      "source": [
        "A continuación crearemos el primero nodo del grafo bajo el nombre de *AddGate*, el cual tendrá como objetivo implementar la operación de suma binaria (2 operandos). En sus atributos, almacenará los dos operandos recibidos (x e y) y el valor resultante ( z ). Estos 3 atributos deberán ser del tipo *Var* anteriormente definido.\n",
        "\n",
        "Además, esta clase implementa los métodos forward y backward. El primero de ellos hará el \"paso adelante\" de los datos, ejecutando la suma y retornando el valor resultante. El segundo, hará el \"paso hacia atrás\" de los datos calculando el gradiente de las variables x e y. Como vimos en clases, la derivada local de la suma toma un valor 1, el cual es multiplicado por el producto de gradientes que vienen desde el final de la red, siguiendo la lógica de la regla de la cadena."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7g_fs1hp65r"
      },
      "source": [
        "class AddGate( object ):\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.z = None\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.z = Var(self.x.value + self.y.value, 0.0)\n",
        "    return self.z\n",
        "  def backward(self):\n",
        "    self.x.grad += 1 * self.z.grad\n",
        "    self.y.grad += 1 * self.z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuXdPXbOyxJQ"
      },
      "source": [
        "A continuación, crearemos el segundo nodo bajo el nombre de *MulGate*, el cual tendrá como objetivo implementar la operación de multiplicación binaria (2 operandos). En sus atributos, almacenará los dos operandos recibidos (x e y) y el valor resultante ( z ). Estos 3 atributos deberán ser del tipo *Var* anteriormente definido.\n",
        "\n",
        "Al igual que la clase anterior, esta clase implementa los métodos forward y backward. El primero de ellos hará el \"paso adelante\" de los datos, ejecutando la multiplicación y retornando el valor resultante. El segundo, hará el \"paso hacia atrás\" de los datos calculando el gradiente de las variables x e y. Como vimos en clases, la derivada local de la multiplicación toma el valor del operando *contrario*, es decir, la derivada de la multiplicación con respecto a x es y, y la derivada de la multiplicación con respecto a y es x. Finalmente, los gradientes locales para cada variable son multiplicados por el producto de gradientes que vienen desde el final de la red, siguiendo la lógica de la regla de la cadena.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCA5g_89qMUR"
      },
      "source": [
        "class MulGate( object ):\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.z = None\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.z = Var(self.x.value * self.y.value, 0.0)\n",
        "    return self.z\n",
        "  def backward(self):\n",
        "    self.x.grad += self.y.value * self.z.grad\n",
        "    self.y.grad += self.x.value * self.z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVyRJy7zrFA"
      },
      "source": [
        "A continuación, crearemos el tercer nodo bajo el nombre de SigmoidGate, el cual tendrá como objetivo implementar la función sigmoide. En sus atributos, almacenará el argumento recibido (x) y el valor resultante (z). Estos 2 atributos deberán ser del tipo *Var* anteriormente definido.\n",
        "\n",
        "Al igual que la clase anterior, esta clase implementa los métodos *forward* y *backward*. El primero de ellos hará el \"paso adelante\" de los datos, evaluando el argumento en la función sigmoide y retornando el valor resultante. El segundo, hará el \"paso hacia atrás\" de los datos calculando el gradiente de la variable x. Como vimos en clases, la derivada local de la sigmoide puede ser calculada en términos de su salida mediante la expresión s * (1-s). Por esta razón, calculamos el gradiente local a partir del valor de z (salida), y luego, multiplicamos por el producto de gradientes que vienen desde el final de la red, siguiendo la lógica de la regla de la cadena.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3avX4FDNqZgh"
      },
      "source": [
        "class SigmoidGate( object ):\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.z = None\n",
        "  def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    self.z = Var(SigmoidGate.sigmoid(self.x.value), 0.0)\n",
        "    return self.z\n",
        "  def backward(self):\n",
        "    s = self.z.value\n",
        "    self.x.grad += s * (1-s) * self.z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebDbv7md1X5N"
      },
      "source": [
        "A continuación, crearemos el cuarto nodo bajo el nombre de LossGate, el cual tendrá como objetivo implementar la función que calcula el error entre la salida actual de la red y el valor deseado. En sus atributos, almacenará los argumentos recibidos (x e y) y el valor resultante (z). Estos 3 atributos deberán ser del tipo *Var* anteriormente definido.\n",
        "\n",
        "Una vez más, esta clase implementa los métodos *forward* y *backward*. El primero de ellos hará el *paso adelante* de los datos, evaluando los argumentos en la función *Mean Square Error* y retornando el valor resultante. El segundo, hará el *paso hacia atrás* de los datos calculando el gradiente de las variables x e y. En este caso, la derivada local corrsponde a las derivadas parciales de la función MSE con respectoa x e y. La primera de ellas corresponde a (x - y), y la segunda a -(x-y). Cada uno de estos gradientes locales es multiplicado por el producto de gradientes que vienen desde el final de la red, siguiendo la lógica de la regla de la cadena."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yya3NwUC1W2Z"
      },
      "source": [
        "class LossGate( object ):\n",
        "  def __init__( self ):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.z = None\n",
        "  def mse(x, y):\n",
        "    return 0.5*(x.value-y.value)**2\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.z = Var(LossGate.mse(self.x, self.y), 0.0)\n",
        "    return self.z\n",
        "  def backward(self):\n",
        "    self.x.grad += (self.x.value-self.y.value) * self.z.grad\n",
        "    self.y.grad += -1.0*(self.x.value-self.y.value) * self.z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwZyR1tF-z2z"
      },
      "source": [
        "A continuación definiremos los objetos que contendrán las variables y nodos del grafo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMCLuQserIqK"
      },
      "source": [
        "# Value definition\n",
        "w0 = Var(2.0, 0.0)  # weight 0\n",
        "w1 = Var(-3.0, 0.0) # weight 1\n",
        "w2 = Var(-3.0, 0.0) # weight 2\n",
        "x = Var(-1.0, 0.0)  # input x\n",
        "y = Var(-2.0, 0.0)  # input y\n",
        "t = Var(0.5, 0.0)   # targe t\n",
        "\n",
        "# Gate definition\n",
        "mulg0 = MulGate()\n",
        "mulg1 = MulGate()\n",
        "addg0 = AddGate()\n",
        "addg1 = AddGate()\n",
        "sg0 = SigmoidGate()\n",
        "lg0 = LossGate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm1l4Tl4_Uyq"
      },
      "source": [
        "Para armar la secuencia completa de operaciones que realiza nuestro perceptrón, implementaremos la función forwardNetwork que tomará las variables creadas y las pasará a través de los nodos, retornando a la salida el valor del error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtmSIxymrJcV"
      },
      "source": [
        "# forward pass\n",
        "def forwardNetwork():\n",
        "  w0x = mulg0.forward(w0, x)\n",
        "  w1y = mulg1.forward(w1, y)\n",
        "  w0xpw1y = addg0.forward(w0x, w1y)\n",
        "  w0xpw1ypw2 = addg1.forward(w0xpw1y, w2)\n",
        "  neuron_output = sg0.forward(w0xpw1ypw2)\n",
        "  loss = lg0.forward(neuron_output, t)\n",
        "  return loss, neuron_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiw2bPwbAJHa"
      },
      "source": [
        "De manera similar, implementaremos la función backwardNetwork que hará el paso inverso desde la función de error hasta los nodos de multiplicación. Note la asignación del valor 1 al gradiente de la variable de error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DXo_dJ4rMlj"
      },
      "source": [
        "# backward pass\n",
        "def backwardNetwork( e ):\n",
        "  e.grad = 1.0\n",
        "  lg0.backward()\n",
        "  sg0.backward()\n",
        "  addg1.backward()\n",
        "  addg0.backward()\n",
        "  mulg1.backward()\n",
        "  mulg0.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YMJufMjHPBG"
      },
      "source": [
        "A continuación se implementa el loop de entrenamiento mediante el método del descenso del gradiente. Como primer paso, se establece el valor del *learning rate* en 0.01, el cual corresponde al parámetro $\\eta$ visto en clases.\n",
        "\n",
        "Posteriormente, se hace un llamado a la función *forwardNetwork* para hacer el paso hacia adelante, obteniendo como resultado la variable de error y salida del perceptrón. Antes de entrar al loop, se imprime el valor inicial predicho por la red.\n",
        "\n",
        "Al entrar al loop *while*, se establece como condición de término que el valor del error sea menor o igual a $1^{-4}$, lo cual definirá el grado de precisión que alcanzará nuestro modelo. Una vez dentro del loop, se llama a la función *backwardNetwork* para propagar los gradientes hacia atrás, y luego, se actualizan los pesos de la red según la regla de actualización definida por el método del descenso del gradiente. Luego de esto, se hace un nuevo llamado a la función *forwardNetwork* para pasar los datos hacia adelante y continuar estos pasos de forma iterativa. En cada paso, imprimiremos el valor que va tomando el error.\n",
        "\n",
        "Finalmente, imprimimos el último valor que predijo el perceptrón durante su entrenamiento, el cual deberá ser cercano al valor objetivo, es decir, cercano a 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxeordYMBfp1"
      },
      "source": [
        "# gradient descent\n",
        "import time\n",
        "learning_rate = 0.01;\n",
        "e, neuron_output = forwardNetwork()\n",
        "print( 'First output value: %.4f' % (neuron_output.value) )\n",
        "while e.value > 1e-4:\n",
        "  backwardNetwork( e )\n",
        "  w0.value -= learning_rate * w0.grad\n",
        "  w1.value -= learning_rate * w1.grad\n",
        "  w2.value -= learning_rate * w2.grad\n",
        "  e, neuron_output = forwardNetwork()\n",
        "  print( 'current loss: %.4f' % (e.value) )\n",
        "  time.sleep(0.25)\n",
        "print( 'Last output value: %.4f' % (neuron_output.value) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qm9c16LmhxR"
      },
      "source": [
        "## Experimento 2: Construcción de grafo de cómputo de alto nivel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kEHrTg0KXLy"
      },
      "source": [
        "En el experimento anterior logramos entrenar un perceptrón a través de la construcción de un grafo de cómputo, el cual se construyó a partir de nodos que implementaron operaciones básicas como sumas y multiplicaciones. Sin embargo, también vimos que era posible crear nodos más complejos que incluian varias operaciones básicas dentro de ellos, como fue el caso de la función sigmoidal y pérdida.\n",
        "\n",
        "Según lo anterior, y considerando que para las arquitecturas de redes neuronales vistas solo interesa el valor del gradiente propagado hasta los pesos, en este experimento armaremos un bloque completo llamado perceptrón, el cual almacenará los gradientes de los pesos, entradas y salida, y no, el de operaciones intermedias.\n",
        "\n",
        "La siguiente figura muestra como haremos la reagrupación de bloques:\n",
        "\n",
        "<img src=\"https://imgur.com/UhtpMvS.png\" />\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXHUmbGemjxn"
      },
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xflbVmT0SCtV"
      },
      "source": [
        "Hemos modificado la clase *Var* para que esta vez pueda recibir vectores de numpy como valor. Por esta razón, sus gradientes son inicializados como un vector de ceros con igual dimensión que el vector de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVWuiKbkm-sg"
      },
      "source": [
        "class Var(object):\n",
        "  def __init__(self, value, grad = None):\n",
        "    self.value = value\n",
        "    if grad == None:\n",
        "      self.grad = np.zeros(value.shape)\n",
        "    else:\n",
        "      self.grad = grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKh9EIUxSa92"
      },
      "source": [
        "A continuación definimos el nodo perceptrón. Su método *forward* recibirá como argumento un vector de pesos y uno de entradas. Con ellos, calculará su producto punto (multiplicación elemento a elemento, y luego suma) y luego aplicará la función sigmoidal sobre el valor resultante.\n",
        "\n",
        "Por otro lado, el método *backward* calculará el vector de gradientes para los vectores de pesos y entradas. Para ello, multiplicará el gradiente recibido desde el \"lado derecho\" de la red (z.grad), por el gradiente local de la sigmoide (s*(1-s)), y por el valor de la variable contraria que representa el gradiente local de la multiplicación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQsyYCpnAXx"
      },
      "source": [
        "class PerceptronGate(object):\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.z = None\n",
        "  def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    dotProd = self.x.value.dot(self.y.value)\n",
        "    s = PerceptronGate.sigmoid(dotProd)\n",
        "    self.z = Var(s, 0.0)\n",
        "    return self.z\n",
        "  def backward(self):\n",
        "    s = self.z.value\n",
        "    self.x.grad += self.y.value * s * (1 - s) * self.z.grad\n",
        "    self.y.grad += self.x.value * s * (1 - s) * self.z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGbUVHU6nCvH"
      },
      "source": [
        "class LossGate(object):\n",
        "  def __init__(self):\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    self.z = None\n",
        "  def forward(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.z = Var(0.5*(self.x.value-self.y.value)**2, 0.0)\n",
        "    return self.z\n",
        "  def backward(self):\n",
        "    self.x.grad += (self.x.value-self.y.value) * self.z.grad\n",
        "    self.y.grad += -1.0*(self.x.value-self.y.value) * self.z.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDUGmAwSTold"
      },
      "source": [
        "A continuación, definiremos el vector de pesos (w) y entrada (x), además de la salida deseada o target (t). Además, definiremos los nodos para el perceptrón y función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPxIiNL7nE4U"
      },
      "source": [
        "# value and gates definition\n",
        "w = Var(np.array([2.0,-3.0,-3.0]))\n",
        "x = Var(np.array([-1.0, -2.0, 1.0]))\n",
        "t = Var(np.array([0.5]))\n",
        "\n",
        "perceptron = PerceptronGate()\n",
        "loss = LossGate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPbKkrpPUHUf"
      },
      "source": [
        "Definición de función forward que arma la estructura del grafo de cómputo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUw56FVmnGk9"
      },
      "source": [
        "# forward pass\n",
        "def forwardNetwork():\n",
        "  p = perceptron.forward(w,x)\n",
        "  l = loss.forward(p,t)\n",
        "  return l, p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcZ9inJ5UYXs"
      },
      "source": [
        "Definición de función backward que arma la estructura inversa del grafo de cómputo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKwp6jTjnIT9"
      },
      "source": [
        "# backward pass\n",
        "def backwardNetwork( output ):\n",
        "  output.grad = 1.0;\n",
        "  loss.backward()\n",
        "  perceptron.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47aTdE2UexG"
      },
      "source": [
        "A continuación vemos el loop de entrenamiento. Éste es similar al anterior, salvo por la diferencia de que la actualización de pesos se realiza en una sola línea aprocechando el hecho de que todos se encuentran en un vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q_mXPmOnJ7O"
      },
      "source": [
        "# gradient descent\n",
        "learning_rate = 0.01;\n",
        "e, neuron_output = forwardNetwork()\n",
        "print( 'First output value: %.4f' % (neuron_output.value) )\n",
        "while e.value > 1e-4:\n",
        "  backwardNetwork( e )\n",
        "  w.value -= learning_rate * w.grad \n",
        "  e, neuron_output = forwardNetwork()\n",
        "  print( 'current loss: %.4f' % (e.value) )\n",
        "  time.sleep(0.25)\n",
        "print( 'First output value: %.4f' % (neuron_output.value) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVUgM5taN_R2"
      },
      "source": [
        "## Experimento 3: ¿ Cómo entrenar nuestro perceptrón en pytorch ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTOjGzqpODwX"
      },
      "source": [
        "En este punto cabe preguntarse, ¿ cómo implementaríamos el experimento anterior utilizando pytorch ?.\n",
        "\n",
        "A continuación se muestra un código de ejemplo para el entrenamiento de un perceptrón bajo las mismas condiciones que el experimento anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqN_a86wOJzh"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "w = torch.Tensor( [2.0,-3.0,-3.0] )\n",
        "x = torch.Tensor( [-1.0, -2.0] )\n",
        "t = torch.Tensor( [0.5] )\n",
        "\n",
        "class Perceptron( nn.Module ):\n",
        "  def __init__( self, weights ):\n",
        "    super( Perceptron, self ).__init__()\n",
        "    self.layer = nn.Linear( 2, 1 )\n",
        "    with torch.no_grad():\n",
        "      self.layer.weight.copy_( weights[:2] )\n",
        "      self.layer.bias.copy_( weights[2] )\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  def forward( self, x ):\n",
        "    x = self.sigmoid( self.layer(x) )\n",
        "    return x\n",
        "\n",
        "model = Perceptron( w )\n",
        "mse_loss = nn.MSELoss()\n",
        "optimizer = optim.SGD( model.parameters(), lr = 0.01 ) # Learning rate equal to 0.01\n",
        "\n",
        "p = model( x )          # forward step\n",
        "loss_value = mse_loss( p, t )\n",
        "print( 'First output value: %.4f' % (p) )\n",
        "while loss_value.item() > 1e-4:\n",
        "  loss_value.backward() # backward step\n",
        "  optimizer.step()      # weights update\n",
        "  p = model( x )        # forward step\n",
        "  loss_value = mse_loss( p, t )\n",
        "  print( 'current loss: %.4f' % (loss_value.item()) )\n",
        "print( 'Last output value: %.4f' % (p) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19knwwdcZKo3"
      },
      "source": [
        "## Actividades (opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oILMcIAhnP-C"
      },
      "source": [
        "### Actividad 2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05AVkg7tl74b"
      },
      "source": [
        "Utilizando los conceptos y estructuras vistas en los experimentos anteriores, programe una red neuronal de dos capas como la que se muestra en la siguiente figura:\n",
        "\n",
        "<img src=\"https://imgur.com/eb9miM2.png\" />\n",
        "\n",
        "Esta red recibirá como entrada un vector de 10 dimensiones, tendrá una capa oculta de 3 neuronas y una capa de salida de 1 neurona. Para su implementación, deberá basarse en los nodos de perceptrón y función de pérdida vistos en los experimentos anteriores.\n",
        "\n",
        "Con esta estructura, deberá aprender un modelo que reciba un vector de 10 dimensiones definido por usted (manualmente o generado de forma aleatoria), y el valor de salida 0.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU3l93h4ZkPZ"
      },
      "source": [
        "# Inserte aquí su código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gch1aN5l60Yo"
      },
      "source": [
        "# **Inicialización de Pesos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9en6OsOx13P1"
      },
      "source": [
        "En la siguiente sección analizaremos el afecto que tiene el criterio de inicialización de pesos escogido, sobre el proceso de entrenamiento de una red neuronal profunda.\n",
        "\n",
        "Para ello, crearemos una red neuronal de 10 capas, que recibirá como entrada un vector de 2 dimensiones, y entregará a la salida un único valor. Esta red será construida sin utilizar función de activación en ninguna de sus capas, con el objetivo de medir de forma aislada el efecto de los valores iniciales de los pesos. La siguiente figura, muestra un esquema de la red neuronal diseñada:\n",
        "\n",
        "<img src=\"https://imgur.com/O9acV99.png\"/>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4DPyT3m64-w"
      },
      "source": [
        "## Experimento 1: Inicialización con valor constante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6maURe-s8AyZ"
      },
      "source": [
        "Antes de comenzar, importaremos los paquetes necesarios para el desarrollo de esta sección. Con ellos, definiremos la función *plot_variable* que nos permitirá graficar de forma sencilla el valor de los gradientes, y la función *fit*, que implementará el loop de entrenamiento entregando como único valor de entrada el vector $[0.5, 0.5]$, para la predicción del valor 1.\n",
        "\n",
        "Por ahora, no nos enfocaremos en su implementación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2zlqCVSfNvd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huMWX5-Ks3xG"
      },
      "source": [
        "def plot_variable( grads, varname ):\n",
        "  plt.figure( figsize=(9, 6) )\n",
        "  ax = plt.axes()\n",
        "  ax.set_xlabel( 'Training step' )\n",
        "  ax.set_ylabel( varname )\n",
        "  ax.plot( grads )\n",
        "  ax.update_datalim( list( zip( range(len(grads)), grads ) ) )\n",
        "  ax.autoscale()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmW3LNJj-HH1"
      },
      "source": [
        "def fit( model ):\n",
        "  mse_lossfunc = nn.MSELoss()\n",
        "  optimizer = optim.Adam( model.parameters(), lr = 1e-4 )\n",
        "  x = torch.Tensor( [0.5, 0.5] )\n",
        "  y = torch.Tensor( [1] )\n",
        "  gradients = list()\n",
        "  loss_seq = list()\n",
        "  for i in range( 200 ):\n",
        "    p = model( x )\n",
        "    loss_value = mse_lossfunc( p, y )\n",
        "    optimizer.zero_grad()\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "    gradients.append( model.layer_0.weight.grad[0,:] )\n",
        "    loss_seq.append( loss_value.item() )\n",
        "  gradients = torch.stack( gradients )\n",
        "  loss_seq = torch.Tensor( loss_seq )\n",
        "  plot_variable( gradients[:,0], 'Gradient' )\n",
        "  plot_variable( loss_seq, 'Loss' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXGMVh7FlKw"
      },
      "source": [
        "En el siguiente código hemos definido el modelo *DeepNN*. Éste implementa una red neuronal con 9 capas ocultas de 2 neuronas, y una capa de salida de 1 neurona, y sin utilizar función de activación.\n",
        "\n",
        "Cada capa es definida mediante la creación de un objeto de la clase *Linear* de torch, las cuales son almacenadas dentro de los atributos de nombre *layer_x*. Una vez creadas las 10 capas, utilizaremos la función *init.constant_* de torch para inicializar los pesos de cada capa a un valor constante, el cual es definido por un parámetro del constructor de la clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF04nnZiFd-h"
      },
      "source": [
        "class DeepNN( nn.Module ):\n",
        "\n",
        "  def __init__( self, weights_initial_value ):\n",
        "    super( DeepNN, self ).__init__()\n",
        "    self.layer_0 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_1 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_2 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_3 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_4 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_5 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_6 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_7 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_8 = torch.nn.Linear( 2, 2 )\n",
        "    self.layer_9 = torch.nn.Linear( 2, 1 )\n",
        "    torch.nn.init.constant_( self.layer_0.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_1.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_2.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_3.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_4.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_5.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_6.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_7.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_8.weight.data, weights_initial_value )\n",
        "    torch.nn.init.constant_( self.layer_9.weight.data, weights_initial_value )\n",
        "\n",
        "  def forward( self, x ):\n",
        "    x = self.layer_0(x)\n",
        "    x = self.layer_1(x)\n",
        "    x = self.layer_2(x)\n",
        "    x = self.layer_3(x)\n",
        "    x = self.layer_4(x)\n",
        "    x = self.layer_5(x)\n",
        "    x = self.layer_6(x)\n",
        "    x = self.layer_7(x)\n",
        "    x = self.layer_8(x)\n",
        "    x = self.layer_9(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbxLQ3iZswW0"
      },
      "source": [
        "### Inicialización de pesos con valores menor a 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pYMy3DbEz2D"
      },
      "source": [
        "Nuestro primer experimento consistirá en iniciazar la red con todos sus pesos con un valor menor que uno. En particular, el valor escogido es 0.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyz7BudvtVtO"
      },
      "source": [
        "model = DeepNN( 0.1 )\n",
        "print(model.layer_0.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH09hMfqFB_L"
      },
      "source": [
        "Ahora, veamos que pasa con los gradientes y la pérdida al entrenar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg5wqCmqkT3d"
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zzY7EAy8cV1"
      },
      "source": [
        "### Inicialización de pesos con valores mayor a 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkVZs9tZGCau"
      },
      "source": [
        "En el presente experimento, inicializaremos la red con todos sus pesos con un valor mayor a 1. En particular, el valor escogido es 1.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF9bh7JP8yzv"
      },
      "source": [
        "model = DeepNN( 1.5 )\n",
        "print(model.layer_0.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIo7bmv-Gbw5"
      },
      "source": [
        "Ahora, veamos que pasa con los gradientes y la pérdida al entrenar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwfWefiA84ed"
      },
      "source": [
        "fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSZ6LkFc3z_D"
      },
      "source": [
        "## Actividades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7LBCq8zdQwP"
      },
      "source": [
        "### Actividad 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LovSBbxudVU-"
      },
      "source": [
        "Responda las siguientes preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDwE-r3ZdYCZ"
      },
      "source": [
        "¿ Como se llama el fenómeno observado al inicializar los pesos con valores menor a 1 ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEjSr1PKdff4"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBIojow6df7J"
      },
      "source": [
        "¿ Como se llama el fenómeno observado al inicializar los pesos con valores mayor a 1 ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2HPtAwgdgTr"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr6SxpSo77kn"
      },
      "source": [
        "### Actividad 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWjmackBMb0a"
      },
      "source": [
        "Repita el ejercicio anterior, pero esta vez, incializando los pesos a través del método de Xavier Glorot.\n",
        "\n",
        "Para ello deberá re-definir el modelo y reemplazar la función de inicialización por la función *torch.nn.init.xavier_uniform_*. Para mayor detalle sobre esta función, visite el sitio: https://pytorch.org/docs/stable/_modules/torch/nn/init.html#xavier_uniform_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBX9Y7M2zamc"
      },
      "source": [
        "# Ingrese el código para el modelo de su red"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoMicb9s9GDS"
      },
      "source": [
        "# Ingrese el código para crear una instancia de su modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQG8fViD9Gj8"
      },
      "source": [
        "# Ingrese el código que llama a la función fit, entregando su modelo como parámetro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zciF2l1zNXta"
      },
      "source": [
        "¿ Qué efecto puede ver de la aplicación de este nuevo método de inicialización de pesos ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxGAtUFiNvhD"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wr0XSPvNo8W"
      },
      "source": [
        "¿ A que se deben los efectos observados ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YczgDKDNtLp"
      },
      "source": [
        "**Respuesta:**"
      ]
    }
  ]
}