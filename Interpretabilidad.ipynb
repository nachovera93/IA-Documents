{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interpretabilidad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGk+3l3gha2aWvnapINOhD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nachovera93/IA-Documents/blob/main/Interpretabilidad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR02fBwEiz_q"
      },
      "source": [
        "##**Interpretabilidad**\n",
        "\n",
        "<br>\n",
        "\n",
        "La interpretabilidad en este contexto sería la capacidad de poder observar en que se esta fijando la red para generar ejemplos.\n",
        "\n",
        "* Visualización de caracteristicas responde las preguntas de la red, o que esta mirando la red para generar ejemplos.\n",
        "* Atribuciones estudia que parte de un ejemplo es responsable de la activación de una parte de la red.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "###**Feature Visualization**\n",
        "\n",
        "<br>\n",
        "\n",
        "Las redes son diferenciables con respecto a sus inputs.\n",
        "* Podemos generar una imagen que maximiza la parte deseada de la red.\n",
        "\n",
        "<br>\n",
        "\n",
        "![1](https://drive.google.com/uc?export=view&id=1jpLZAQk5umsL3jX5E72IUT8BZHmjqURI)\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "![2](https://drive.google.com/uc?export=view&id=1We7U1zE5adxExBT1TMzF9NUw22szuhIM)\n",
        "\n",
        "<br>\n",
        "\n",
        "Podemos buscar varios tipos de entrada, de una neurona, canal, capa, clase, etc.\n",
        "\n",
        "<br>\n",
        "\n",
        "![3](https://drive.google.com/uc?export=view&id=1I-TPQlu5wHgIHMS4uh-ZiA2TI5LDi9JZ)\n",
        "\n",
        "<br>\n",
        "\n",
        "Podemos ocupar los logits o la probabilidad de la clase para optimizar, pero si se pptimiza el logits se obtiene una mejor imagen:\n",
        "\n",
        "\n",
        "![4](https://drive.google.com/uc?export=view&id=1os_mKx12SlHLMrnDmdznS-3OhIIeII7h)\n",
        "\n"
      ]
    }
  ]
}